{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "CellCount.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVH-tWxvGpWg",
        "colab_type": "text"
      },
      "source": [
        "## Set up\n",
        "\n",
        "The first cell configures the Google Colab environment to allow the repo to execute properly. Simply \"Run All\" to get started."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42XoC_v9FRNC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "outputId": "f47b4da1-733d-4b99-bd3b-9618fa3476e6"
      },
      "source": [
        "# Necessary installs to get code working on Google colab\n",
        "!pip install libtiff\n",
        "!git clone https://github.com/Shu244/Cytometry-for-Google-Colab.git\n",
        "\n",
        "# Updating environment variables\n",
        "import sys\n",
        "sys.path.append(\"/content/Cytometry-for-Google-Colab\")\n",
        "sys.path.append(\"/content/Cytometry-for-Google-Colab/Mask RCNN\")\n",
        "\n",
        "# Downgrading Tensorflow version\n",
        "!pip install tensorflow-gpu==1.15.0\n",
        "!pip install tensorflow==1.15.0\n",
        "\n",
        "import tensorflow as tf\n",
        "assert (tf.__version__ == \"1.15.0\"), \"Restart runtime to use newly installed Tensorflow\"\n",
        "\n",
        "# Download pretrained COCO parameters\n",
        "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
        "\n",
        "# Unzip data\n",
        "!unzip /content/Cytometry-for-Google-Colab/Data.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: libtiff in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "fatal: destination path 'Cytometry-for-Google-Colab' already exists and is not an empty directory.\n",
            "Requirement already satisfied: tensorflow-gpu==1.15.0 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.18.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.28.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.2.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.15.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.10.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (46.1.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.2.1)\n",
            "Requirement already satisfied: tensorflow==1.15.0 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.28.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.2.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:09:15.022782Z",
          "start_time": "2020-04-15T21:09:02.480621Z"
        },
        "id": "fWMgiLuZy8Np",
        "colab_type": "code",
        "outputId": "6d5ebcc1-6095-4f27-8782-d6207850df50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Set matplotlib backend\n",
        "# This has to be done before other importa that might\n",
        "# set it, but only if we're running in script mode\n",
        "# rather than being imported.\n",
        "'''\n",
        "if __name__ == '__main__':\n",
        "    import matplotlib\n",
        "    # Agg backend runs without a display\n",
        "    matplotlib.use('Agg')\n",
        "    import matplotlib.pyplot as plt\n",
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import json\n",
        "import datetime\n",
        "import xlrd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "from imgaug import augmenters as iaa\n",
        "from libtiff import TIFF, TIFFfile\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Results directory\n",
        "# Save submission files here\n",
        "RESULTS_DIR = os.path.join(ROOT_DIR, \"results/cellcount/\")\n",
        "\n",
        "from MRCNN.config import Config\n",
        "import MRCNN.model as modellib\n",
        "from MRCNN import utils, visualize\n",
        "\n",
        "DataSize=100\n",
        "Validation_ratio=0.1\n",
        "Data_IDS=np.arange(1,DataSize+1,dtype=np.int16) \n",
        "VAL_IMAGE_IDS = np.random.choice(Data_IDS,size=np.int(Validation_ratio*DataSize),replace=False)\n",
        "VAL_IMAGE_IDS.sort()\n",
        "\n",
        "#####################################################\n",
        "#         Configuration\n",
        "#####################################################\n",
        "class CellCountConfig(Config):\n",
        "    NAME = 'CellCount'\n",
        "    \n",
        "    # Train on 1 GPU and 2 images per GPU.\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1 # Background + RedBloodCell\n",
        "    \n",
        "    # Don't exclude based on confidence. Since we have two classes\n",
        "    # then 0.5 is the minimum anyway as it picks between nucleus and BG\n",
        "    DETECTION_MIN_CONFIDENCE = 0\n",
        "    \n",
        "    # Backbone network architecture\n",
        "    # Supported values are: resnet50, resnet101\n",
        "    BACKBONE = \"resnet101\"\n",
        "    \n",
        "    # Input image resizing\n",
        "    IMAGE_RESIZE_MODE = \"pad64\"\n",
        "    IMAGE_MIN_DIM = 812\n",
        "    IMAGE_MAX_DIM = 1280\n",
        "    IMAGE_SHAPE= (832, 1280, 3)\n",
        "    \n",
        "    IMAGE_CHANNEL_COUNT = 3   \n",
        "    \n",
        "    # Length of square anchor side in pixels\n",
        "    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)\n",
        "    \n",
        "    # Number of ROIs per image to feed to classifier/mask heads\n",
        "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
        "    # enough positive proposals to fill this and keep a positive:negative\n",
        "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
        "    # the RPN NMS threshold.\n",
        "    TRAIN_ROIS_PER_IMAGE = 128\n",
        "\n",
        "    # Maximum number of ground truth instances to use in one image\n",
        "    MAX_GT_INSTANCES = 100\n",
        "\n",
        "    # Max number of final detections per image\n",
        "    DETECTION_MAX_INSTANCES = 200\n",
        "    \n",
        "    \n",
        "    # Use a small epoch since the data is simple\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    # use small validation steps since the epoch is small\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "    \n",
        "    # Non-max suppression threshold to filter RPN proposals.\n",
        "    # You can increase this during training to generate more propsals.\n",
        "    #RPN_NMS_THRESHOLD = 0.9\n",
        "    RPN_NMS_THRESHOLD=0.95\n",
        "    \n",
        "    # ROIs kept after non-maximum supression (training and inference)\n",
        "    POST_NMS_ROIS_TRAINING = 500\n",
        "    POST_NMS_ROIS_INFERENCE = 1000\n",
        "    \n",
        "    # Image mean (RGB)\n",
        "    MEAN_PIXEL = (126,126,126)\n",
        "        \n",
        "    # If enabled, resizes instance masks to a smaller size to reduce\n",
        "    # memory load. Recommended when using high-resolution images.\n",
        "    USE_MINI_MASK = True\n",
        "    #MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
        "    MINI_MASK_SHAPE = (100,100)\n",
        "\n",
        "    # Number of ROIs per image to feed to classifier/mask heads\n",
        "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
        "    # enough positive proposals to fill this and keep a positive:negative\n",
        "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
        "    # the RPN NMS threshold.\n",
        "    #TRAIN_ROIS_PER_IMAGE = 128\n",
        "    TRAIN_ROIS_PER_IMAGE = 256\n",
        "    \n",
        "\n",
        "#####################################################\n",
        "#         Dataset\n",
        "#####################################################\n",
        "class CellDataset(utils.Dataset):\n",
        "    \n",
        "    def Image_gen(self, FileName):\n",
        "        self.frame=0\n",
        "        self.ImgeFile=FileName\n",
        "        tif=TIFF.open(FileName)\n",
        "        for Image_gened in tif.iter_images():\n",
        "        #Image = imread(FileName,1)\n",
        "            self.frame+=1\n",
        "            yield Image_gened  \n",
        "    \n",
        "    def Image_getFrame(self, Image_dir, Frame):\n",
        "        #if self.ImgeFile!=Image_dir or self.frame > Frame:\n",
        "        Image_gen=self.Image_gen(Image_dir)\n",
        "        self.frame=0\n",
        "        im_getFrame=[]\n",
        "        while self.frame<Frame:\n",
        "            im_getFrame= next(Image_gen)\n",
        "        im_getFrame=np.array(im_getFrame)\n",
        "        return im_getFrame\n",
        "            \n",
        "    def load_cells(self, dataset_dir, subset):\n",
        "        \"\"\"\n",
        "        Load a subset of the cell dataset.\n",
        "        dataset_dir: Root directory of the dataset\n",
        "        subset: Subset to load. \n",
        "                * train: training data excluding validation images\n",
        "                * val: validation images from VAL_IMAGE_IDS\n",
        "        \"\"\"\n",
        "\n",
        "        # Add classes. We have one class.\n",
        "        # Naming the dataset Cells, and the 1st class RedBloodCell\n",
        "        self.add_class(\"Cells\", 1, \"RBC\")\n",
        "        ROOT_PATH=os.path.dirname(os.getcwd())\n",
        "        dataset_dir=os.path.join(ROOT_PATH,\"Data\",dataset_dir)\n",
        "       # Train or validation dataset?\n",
        "        assert subset in [\"train\", \"val\"]\n",
        "        if subset == \"val\":\n",
        "            image_ids = VAL_IMAGE_IDS\n",
        "        else:\n",
        "            # Get image ids from directory names\n",
        "            if subset == \"train\":\n",
        "                image_ids = list(set(Data_IDS) - set(VAL_IMAGE_IDS))\n",
        "        # Add images\n",
        "        for image_id in image_ids:\n",
        "            self.add_image(\n",
        "                \"Cells\",\n",
        "                image_id=image_id,\n",
        "                path=dataset_dir)\n",
        "                  \n",
        "    def load_image (self,image_id):\n",
        "        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
        "        \"\"\"\n",
        "        # Load image\n",
        "        info = self.image_info[image_id]\n",
        "        dataset_dir=info['path']\n",
        "        data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
        "        data=data.sheets()[0]\n",
        "        Image_dir=os.path.join(os.path.dirname(os.getcwd()),data.col_values(0)[1])\n",
        "        image=self.Image_getFrame(Image_dir, info['id'])\n",
        "        # If grayscale. Convert to RGB for consistency.\n",
        "        image=(image/np.max(image)*255).astype(np.float16)\n",
        "        if image.ndim != 3:\n",
        "            image = skimage.color.gray2rgb(image)\n",
        "        # If has an alpha channel, remove it for consistency\n",
        "        if image.shape[-1] == 4:\n",
        "            image = image[..., :3]\n",
        "        return image\n",
        "        \n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        dataset_dir=info['path']\n",
        "        data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
        "        data=data.sheets()[0]\n",
        "        Frame=data.col_values(1)[1:]\n",
        "        ClassName=data.col_values(2)[1:]\n",
        "        \n",
        "        MaskNum=data.col_values(4)[1:]\n",
        "        ImgMask = [(Class,ImgMask) for [Class,ImgMask,frame] in zip(ClassName, MaskNum,Frame) if frame==info['id']]\n",
        "        # Read mask files from .tif image\n",
        "        Mask=[]\n",
        "        ClassID=[]\n",
        "        for i,Img in enumerate(ImgMask):\n",
        "            # Get mask directory from image path\n",
        "            mask_dir = os.path.join(info['path'], \"{}.tif\".format(Img[1]))\n",
        "            #ID=[name['id'] for name in (self.class_info) if name.get('name')==Img[0]]\n",
        "            ID=1\n",
        "            im = cv2.imread(mask_dir,0).astype(np.bool)\n",
        "            Mask.append(im)\n",
        "            ClassID.append(ID)\n",
        "        Mask = np.stack(Mask, axis=-1)\n",
        "        ClassID= np.squeeze(np.array(ClassID))\n",
        "        return Mask,ClassID\n",
        "    \n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"cells\":\n",
        "            return info[\"id\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n",
        "\n",
        "############################################################\n",
        "#  Training\n",
        "############################################################\n",
        "\n",
        "def train(model, dataset_dir, subset):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    # Training dataset.\n",
        "    dataset_train = CellDataset()\n",
        "    dataset_train.load_cells(dataset_dir,\"train\")\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    # Validation dataset\n",
        "    dataset_val = CellDataset()\n",
        "    dataset_val.load_cells(dataset_dir, \"val\")\n",
        "    dataset_val.prepare()\n",
        "    \n",
        "    # Image augmentation\n",
        "    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n",
        "    augmentation = iaa.SomeOf((0, 2), [\n",
        "        iaa.Fliplr(0.5),\n",
        "        iaa.Flipud(0.5),\n",
        "        iaa.OneOf([iaa.Affine(rotate=90),\n",
        "                   iaa.Affine(rotate=180),\n",
        "                   iaa.Affine(rotate=270)]),\n",
        "        iaa.Multiply((0.8, 1.5)),\n",
        "        iaa.GaussianBlur(sigma=(0.0, 5.0))\n",
        "    ])\n",
        "\n",
        "    # If starting from imagenet, train heads only for a bit\n",
        "    # since they have random weights\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                augmentation=augmentation,\n",
        "                epochs=15,\n",
        "                layers='4+')\n",
        "    '''\n",
        "    print(\"Train all layers\")\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=40,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n",
        "    '''"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:22:53.550849Z",
          "start_time": "2020-04-15T21:09:22.980050Z"
        },
        "scrolled": false,
        "id": "17HIwHsny8Ny",
        "colab_type": "code",
        "outputId": "5e622f35-cc86-4ba4-ab8a-e4a81e14e700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
        "    config = CellCountConfig()\n",
        "    #config.display()\n",
        "\n",
        "    # Create model\n",
        "    model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=RESULTS_DIR)\n",
        "\n",
        "    #Load COCO weights\n",
        "    COCO_WEIGHTS_PATH = os.path.join(os.path.dirname(ROOT_DIR), \"mask_rcnn_coco.h5\")\n",
        "    weights_path = COCO_WEIGHTS_PATH\n",
        "\n",
        "    #weights_path = model.get_imagenet_weights()\n",
        "\n",
        "    # Load weights\n",
        "    model.load_weights(weights_path, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "    #model.load_weights(weights_path, by_name=True)\n",
        "    train(model=model, dataset_dir='val', subset='train')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 3s 0us/step\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /content/results/cellcount/cellcount20200428T0118/mask_rcnn_cellcount_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "res4a_branch2a         (Conv2D)\n",
            "bn4a_branch2a          (BatchNorm)\n",
            "res4a_branch2b         (Conv2D)\n",
            "bn4a_branch2b          (BatchNorm)\n",
            "res4a_branch2c         (Conv2D)\n",
            "res4a_branch1          (Conv2D)\n",
            "bn4a_branch2c          (BatchNorm)\n",
            "bn4a_branch1           (BatchNorm)\n",
            "res4b_branch2a         (Conv2D)\n",
            "bn4b_branch2a          (BatchNorm)\n",
            "res4b_branch2b         (Conv2D)\n",
            "bn4b_branch2b          (BatchNorm)\n",
            "res4b_branch2c         (Conv2D)\n",
            "bn4b_branch2c          (BatchNorm)\n",
            "res4c_branch2a         (Conv2D)\n",
            "bn4c_branch2a          (BatchNorm)\n",
            "res4c_branch2b         (Conv2D)\n",
            "bn4c_branch2b          (BatchNorm)\n",
            "res4c_branch2c         (Conv2D)\n",
            "bn4c_branch2c          (BatchNorm)\n",
            "res4d_branch2a         (Conv2D)\n",
            "bn4d_branch2a          (BatchNorm)\n",
            "res4d_branch2b         (Conv2D)\n",
            "bn4d_branch2b          (BatchNorm)\n",
            "res4d_branch2c         (Conv2D)\n",
            "bn4d_branch2c          (BatchNorm)\n",
            "res4e_branch2a         (Conv2D)\n",
            "bn4e_branch2a          (BatchNorm)\n",
            "res4e_branch2b         (Conv2D)\n",
            "bn4e_branch2b          (BatchNorm)\n",
            "res4e_branch2c         (Conv2D)\n",
            "bn4e_branch2c          (BatchNorm)\n",
            "res4f_branch2a         (Conv2D)\n",
            "bn4f_branch2a          (BatchNorm)\n",
            "res4f_branch2b         (Conv2D)\n",
            "bn4f_branch2b          (BatchNorm)\n",
            "res4f_branch2c         (Conv2D)\n",
            "bn4f_branch2c          (BatchNorm)\n",
            "res4g_branch2a         (Conv2D)\n",
            "bn4g_branch2a          (BatchNorm)\n",
            "res4g_branch2b         (Conv2D)\n",
            "bn4g_branch2b          (BatchNorm)\n",
            "res4g_branch2c         (Conv2D)\n",
            "bn4g_branch2c          (BatchNorm)\n",
            "res4h_branch2a         (Conv2D)\n",
            "bn4h_branch2a          (BatchNorm)\n",
            "res4h_branch2b         (Conv2D)\n",
            "bn4h_branch2b          (BatchNorm)\n",
            "res4h_branch2c         (Conv2D)\n",
            "bn4h_branch2c          (BatchNorm)\n",
            "res4i_branch2a         (Conv2D)\n",
            "bn4i_branch2a          (BatchNorm)\n",
            "res4i_branch2b         (Conv2D)\n",
            "bn4i_branch2b          (BatchNorm)\n",
            "res4i_branch2c         (Conv2D)\n",
            "bn4i_branch2c          (BatchNorm)\n",
            "res4j_branch2a         (Conv2D)\n",
            "bn4j_branch2a          (BatchNorm)\n",
            "res4j_branch2b         (Conv2D)\n",
            "bn4j_branch2b          (BatchNorm)\n",
            "res4j_branch2c         (Conv2D)\n",
            "bn4j_branch2c          (BatchNorm)\n",
            "res4k_branch2a         (Conv2D)\n",
            "bn4k_branch2a          (BatchNorm)\n",
            "res4k_branch2b         (Conv2D)\n",
            "bn4k_branch2b          (BatchNorm)\n",
            "res4k_branch2c         (Conv2D)\n",
            "bn4k_branch2c          (BatchNorm)\n",
            "res4l_branch2a         (Conv2D)\n",
            "bn4l_branch2a          (BatchNorm)\n",
            "res4l_branch2b         (Conv2D)\n",
            "bn4l_branch2b          (BatchNorm)\n",
            "res4l_branch2c         (Conv2D)\n",
            "bn4l_branch2c          (BatchNorm)\n",
            "res4m_branch2a         (Conv2D)\n",
            "bn4m_branch2a          (BatchNorm)\n",
            "res4m_branch2b         (Conv2D)\n",
            "bn4m_branch2b          (BatchNorm)\n",
            "res4m_branch2c         (Conv2D)\n",
            "bn4m_branch2c          (BatchNorm)\n",
            "res4n_branch2a         (Conv2D)\n",
            "bn4n_branch2a          (BatchNorm)\n",
            "res4n_branch2b         (Conv2D)\n",
            "bn4n_branch2b          (BatchNorm)\n",
            "res4n_branch2c         (Conv2D)\n",
            "bn4n_branch2c          (BatchNorm)\n",
            "res4o_branch2a         (Conv2D)\n",
            "bn4o_branch2a          (BatchNorm)\n",
            "res4o_branch2b         (Conv2D)\n",
            "bn4o_branch2b          (BatchNorm)\n",
            "res4o_branch2c         (Conv2D)\n",
            "bn4o_branch2c          (BatchNorm)\n",
            "res4p_branch2a         (Conv2D)\n",
            "bn4p_branch2a          (BatchNorm)\n",
            "res4p_branch2b         (Conv2D)\n",
            "bn4p_branch2b          (BatchNorm)\n",
            "res4p_branch2c         (Conv2D)\n",
            "bn4p_branch2c          (BatchNorm)\n",
            "res4q_branch2a         (Conv2D)\n",
            "bn4q_branch2a          (BatchNorm)\n",
            "res4q_branch2b         (Conv2D)\n",
            "bn4q_branch2b          (BatchNorm)\n",
            "res4q_branch2c         (Conv2D)\n",
            "bn4q_branch2c          (BatchNorm)\n",
            "res4r_branch2a         (Conv2D)\n",
            "bn4r_branch2a          (BatchNorm)\n",
            "res4r_branch2b         (Conv2D)\n",
            "bn4r_branch2b          (BatchNorm)\n",
            "res4r_branch2c         (Conv2D)\n",
            "bn4r_branch2c          (BatchNorm)\n",
            "res4s_branch2a         (Conv2D)\n",
            "bn4s_branch2a          (BatchNorm)\n",
            "res4s_branch2b         (Conv2D)\n",
            "bn4s_branch2b          (BatchNorm)\n",
            "res4s_branch2c         (Conv2D)\n",
            "bn4s_branch2c          (BatchNorm)\n",
            "res4t_branch2a         (Conv2D)\n",
            "bn4t_branch2a          (BatchNorm)\n",
            "res4t_branch2b         (Conv2D)\n",
            "bn4t_branch2b          (BatchNorm)\n",
            "res4t_branch2c         (Conv2D)\n",
            "bn4t_branch2c          (BatchNorm)\n",
            "res4u_branch2a         (Conv2D)\n",
            "bn4u_branch2a          (BatchNorm)\n",
            "res4u_branch2b         (Conv2D)\n",
            "bn4u_branch2b          (BatchNorm)\n",
            "res4u_branch2c         (Conv2D)\n",
            "bn4u_branch2c          (BatchNorm)\n",
            "res4v_branch2a         (Conv2D)\n",
            "bn4v_branch2a          (BatchNorm)\n",
            "res4v_branch2b         (Conv2D)\n",
            "bn4v_branch2b          (BatchNorm)\n",
            "res4v_branch2c         (Conv2D)\n",
            "bn4v_branch2c          (BatchNorm)\n",
            "res4w_branch2a         (Conv2D)\n",
            "bn4w_branch2a          (BatchNorm)\n",
            "res4w_branch2b         (Conv2D)\n",
            "bn4w_branch2b          (BatchNorm)\n",
            "res4w_branch2c         (Conv2D)\n",
            "bn4w_branch2c          (BatchNorm)\n",
            "res5a_branch2a         (Conv2D)\n",
            "bn5a_branch2a          (BatchNorm)\n",
            "res5a_branch2b         (Conv2D)\n",
            "bn5a_branch2b          (BatchNorm)\n",
            "res5a_branch2c         (Conv2D)\n",
            "res5a_branch1          (Conv2D)\n",
            "bn5a_branch2c          (BatchNorm)\n",
            "bn5a_branch1           (BatchNorm)\n",
            "res5b_branch2a         (Conv2D)\n",
            "bn5b_branch2a          (BatchNorm)\n",
            "res5b_branch2b         (Conv2D)\n",
            "bn5b_branch2b          (BatchNorm)\n",
            "res5b_branch2c         (Conv2D)\n",
            "bn5b_branch2c          (BatchNorm)\n",
            "res5c_branch2a         (Conv2D)\n",
            "bn5c_branch2a          (BatchNorm)\n",
            "res5c_branch2b         (Conv2D)\n",
            "bn5c_branch2b          (BatchNorm)\n",
            "res5c_branch2c         (Conv2D)\n",
            "bn5c_branch2c          (BatchNorm)\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
            "ERROR:root:Error processing image {'id': 5, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n",
            "ERROR:root:Error processing image {'id': 5, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'ERROR:root:Error processing image {'id': 94, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n",
            "ERROR:root:Error processing image {'id': 88, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n",
            "ERROR:root:Error processing image {'id': 94, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n",
            "ERROR:root:Error processing image {'id': 91, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n",
            "ERROR:root:Error processing image {'id': 39, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n",
            "ERROR:root:Error processing image {'id': 91, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n",
            "\n",
            "ERROR:root:Error processing image {'id': 61, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'ERROR:root:Error processing image {'id': 88, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'ERROR:root:Error processing image {'id': 61, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'ERROR:root:Error processing image {'id': 6, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n",
            "\n",
            "\n",
            "\n",
            "ERROR:root:Error processing image {'id': 25, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'ERROR:root:Error processing image {'id': 39, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'ERROR:root:Error processing image {'id': 25, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'ERROR:root:Error processing image {'id': 3, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n",
            "\n",
            "\n",
            "\n",
            "ERROR:root:Error processing image {'id': 8, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'ERROR:root:Error processing image {'id': 40, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n",
            "ERROR:root:Error processing image {'id': 8, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'ERROR:root:Error processing image {'id': 6, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n",
            "\n",
            "ERROR:root:Error processing image {'id': 4, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n",
            "ERROR:root:Error processing image {'id': 3, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n",
            "\n",
            "ERROR:root:Error processing image {'id': 40, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n",
            "ERROR:root:Error processing image {'id': 4, 'source': 'Cells', 'path': '/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n",
            "    image = dataset.load_image(image_id)\n",
            "  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n",
            "    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 650, in next_sample\n    return six.next(_SHARED_SEQUENCES[uid])\n  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n    use_mini_mask=config.USE_MINI_MASK)\n  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1210, in load_image_gt\n    image = dataset.load_image(image_id)\n  File \"<ipython-input-2-74990fe37fca>\", line 178, in load_image\n    data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n  File \"/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\", line 116, in open_workbook\n    with open(filename, \"rb\") as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-03503945bad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                                 \"mrcnn_bbox\", \"mrcnn_mask\"])\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#model.load_weights(weights_path, by_name=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-74990fe37fca>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset_dir, subset)\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m                 layers='4+')\n\u001b[0m\u001b[1;32m    265\u001b[0m     '''\n\u001b[1;32m    266\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train all layers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2370\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2371\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2372\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2373\u001b[0m         )\n\u001b[1;32m   2374\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m()\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \"\"\"\n\u001b[0;32m--> 650\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1705\u001b[0m                     load_image_gt(dataset, config, image_id, augment=augment,\n\u001b[1;32m   1706\u001b[0m                                 \u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1707\u001b[0;31m                                 use_mini_mask=config.USE_MINI_MASK)\n\u001b[0m\u001b[1;32m   1708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m             \u001b[0;31m# Skip images that have no instances. This can happen in cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\u001b[0m in \u001b[0;36mload_image_gt\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \"\"\"\n\u001b[1;32m   1209\u001b[0m     \u001b[0;31m# Load image and mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1211\u001b[0m     \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \u001b[0moriginal_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-74990fe37fca>\u001b[0m in \u001b[0;36mload_image\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mdataset_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cellLabel.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msheets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mImage_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Data/val/cellLabel.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:26:24.856692Z",
          "start_time": "2020-04-15T21:26:11.833656Z"
        },
        "id": "rlgYbX73y8N3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################\n",
        "#  Detection\n",
        "############################################################\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
        "config = CellCountConfig()\n",
        "\n",
        "#Create Model\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=RESULTS_DIR)\n",
        "\n",
        "#Load weights\n",
        "weights_path= \"results/cellcount/cellcount20200129T0945/mask_rcnn_cellcount_0015.h5\"\n",
        "# Load weights\n",
        "model.load_weights(weights_path, by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:30:39.947165Z",
          "start_time": "2020-04-15T21:30:13.315439Z"
        },
        "id": "Guz4JPA6y8N8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read dataset\n",
        "dataset = CellDataset()\n",
        "dataset.load_cells('val', 'train')\n",
        "dataset.prepare()\n",
        "\n",
        "GT_no=[]\n",
        "DE_no=[]\n",
        "for image_id in range (1,28):\n",
        "    # Load image and run detection\n",
        "    image = dataset.load_image(image_id)\n",
        "    mask,class_id= dataset.load_mask(image_id)\n",
        "    # Detect objects\n",
        "    r = model.detect([image], verbose=0)[0]\n",
        "    # Encode image to RLE. Returns a string of multiple lines\n",
        "    source_id = dataset.image_info[image_id][\"id\"]\n",
        "    #rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
        "    #submission.append(rle)\n",
        "    GT_no.append(np.size(mask,2))\n",
        "    DE_no.append(len(r['class_ids']))\n",
        "    print('--------------------------------')\n",
        "    print('Frame ID =', dataset.image_info[image_id][\"id\"])\n",
        "    print('Ground Truth Cell Number = ', GT_no[-1])\n",
        "    print('Detected Cell Number =', DE_no[-1])\n",
        "    visualize.display_instances(\n",
        "        np.sum(mask,axis=2), r['rois'], r['masks'], r['class_ids'],\n",
        "        dataset.class_names, r['scores'],\n",
        "        show_bbox=False, show_mask=False,\n",
        "        title=\"Predictions\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "GkVJoLK-y8OD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read dataset\n",
        "dataset = CellDataset()\n",
        "dataset.load_cells('val', 'train')\n",
        "dataset.prepare()\n",
        "im_dir='../GFC_505nm_40X1p15NA_PCO_500usexp_160fps_3@0001.tif'\n",
        "image =dataset.Image_getFrame(im_dir,27)\n",
        "if image.ndim != 3:\n",
        "    image = skimage.color.gray2rgb(image)\n",
        "# If has an alpha channel, remove it for consistency\n",
        "if image.shape[-1] == 4:\n",
        "    image = image[..., :3]\n",
        "image=(image/np.max(image)*255).astype(np.float16)\n",
        "# Detect objects\n",
        "r = model.detect([image], verbose=0)[0]\n",
        "# Encode image to RLE. Returns a string of multiple lines\n",
        "source_id = dataset.image_info[image_id][\"id\"]\n",
        "#rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
        "#submission.append(rle)\n",
        "GT_no.append(np.size(mask,2))\n",
        "DE_no.append(len(r['class_ids']))\n",
        "print('--------------------------------')\n",
        "print('Frame ID =', dataset.image_info[image_id][\"id\"])\n",
        "print('Ground Truth Cell Number = ', GT_no[-1])\n",
        "print('Detected Cell Number =', DE_no[-1])\n",
        "#bg=np.zeros(np.shape(image))\n",
        "visualize.display_instances(\n",
        "    image, r['rois'], r['masks'], r['class_ids'],\n",
        "    dataset.class_names, r['scores'],\n",
        "    show_bbox=False, show_mask=False,\n",
        "    title=\"Predictions\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqm6YUJgy8OK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhc6VQnFy8OP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E84KD59y8OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################\n",
        "#  Detection\n",
        "############################################################\n",
        "\n",
        "def detect(model, dataset_dir, subset):\n",
        "    \"\"\"Run detection on images in the given directory.\"\"\"\n",
        "    print(\"Running on {}\".format(dataset_dir))\n",
        "\n",
        "    # Create directory\n",
        "    if not os.path.exists(RESULTS_DIR):\n",
        "        os.makedirs(RESULTS_DIR)\n",
        "    submit_dir = \"submit_{:%Y%m%dT%H%M%S}\".format(datetime.datetime.now())\n",
        "    submit_dir = os.path.join(RESULTS_DIR, submit_dir)\n",
        "    os.makedirs(submit_dir)\n",
        "\n",
        "    # Read dataset\n",
        "    dataset = CellDataset()\n",
        "    dataset.load_cells(dataset_dir, subset)\n",
        "    dataset.prepare()\n",
        "    # Load over images\n",
        "    submission = []\n",
        "    for image_id in dataset.image_ids:\n",
        "        # Load image and run detection\n",
        "        image = dataset.load_image(image_id)\n",
        "        # Detect objects\n",
        "        r = model.detect([image], verbose=0)[0]\n",
        "        # Encode image to RLE. Returns a string of multiple lines\n",
        "        source_id = dataset.image_info[image_id][\"id\"]\n",
        "        rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
        "        submission.append(rle)\n",
        "        # Save image with masks\n",
        "        visualize.display_instances(\n",
        "            image, r['rois'], r['masks'], r['class_ids'],\n",
        "            dataset.class_names, r['scores'],\n",
        "            show_bbox=False, show_mask=False,\n",
        "            title=\"Predictions\")\n",
        "        plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))\n",
        "\n",
        "    # Save to csv file\n",
        "    submission = \"ImageId,EncodedPixels\\n\" + \"\\n\".join(submission)\n",
        "    file_path = os.path.join(submit_dir, \"submit.csv\")\n",
        "    with open(file_path, \"w\") as f:\n",
        "        f.write(submission)\n",
        "    print(\"Saved to \", submit_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf-Dlmoly8OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.max(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHXCLCily8Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}