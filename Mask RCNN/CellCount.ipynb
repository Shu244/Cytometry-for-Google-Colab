{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "CellCount.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVH-tWxvGpWg",
        "colab_type": "text"
      },
      "source": [
        "## Set up\n",
        "\n",
        "Please obtain the raw data zip file and add it to your Google drive. Update line 4 of cell 1 to specify the path for where this data zip file is. \n",
        "\n",
        "The first cell configures the Google Colab environment to allow the repo to execute properly. Simply \"Run All\" to get started."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42XoC_v9FRNC",
        "colab_type": "code",
        "outputId": "f38a50eb-e103-466d-a608-0aa6aa816b4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        }
      },
      "source": [
        "# Getting raw data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip '/content/drive/My Drive/JHU/2020 Spring Semester/Machine Learning: Deep Learning/Final Project/raw image.zip' -d /content/\n",
        "\n",
        "# Organizing raw data\n",
        "import os\n",
        "from shutil import move\n",
        "\n",
        "root = '/content/'\n",
        "for filename in os.listdir(os.path.join(root, 'raw image')):\n",
        "    move(os.path.join(root, 'raw image', filename), os.path.join(root, filename))\n",
        "\n",
        "# Necessary installs to get code working on Google colab\n",
        "!pip install libtiff\n",
        "\n",
        "# Cloning core repo\n",
        "!git clone https://github.com/Shu244/Cytometry-for-Google-Colab.git\n",
        "\n",
        "# Updating environment variables\n",
        "import sys\n",
        "sys.path.append(\"/content/Cytometry-for-Google-Colab/Mask RCNN\")\n",
        "\n",
        "# Downgrading Tensorflow version\n",
        "!pip install tensorflow-gpu==1.15.0\n",
        "\n",
        "import tensorflow as tf\n",
        "assert (tf.__version__ == \"1.15.0\"), \"Restart runtime to use newly installed Tensorflow\"\n",
        "\n",
        "# Download pretrained COCO parameters\n",
        "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5 -P /content/\n",
        "\n",
        "# Unzip data\n",
        "!unzip /content/Cytometry-for-Google-Colab/Data.zip\n",
        "\n",
        "# Change into /content/ directory\n",
        "%cd /content/Cytometry-for-Google-Colab"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archive:  /content/drive/My Drive/JHU/2020 Spring Semester/Machine Learning: Deep Learning/Final Project/raw image.zip\n",
            "  inflating: /content/raw image/GFC_505nm_40X1p15NA_PCO_500usexp_160fps_3.tif  \n",
            "replace /content/__MACOSX/raw image/._GFC_505nm_40X1p15NA_PCO_500usexp_160fps_3.tif? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "  inflating: /content/raw image/GFC_505nm_40X1p15NA_PCO_500usexp_160fps_3@0001.tif  \n",
            "Requirement already satisfied: libtiff in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "fatal: destination path 'Cytometry-for-Google-Colab' already exists and is not an empty directory.\n",
            "Requirement already satisfied: tensorflow-gpu==1.15.0 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.2.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.18.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.15.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.28.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.0) (46.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.0.1)\n",
            "--2020-04-29 19:39:22--  https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200429%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200429T193922Z&X-Amz-Expires=300&X-Amz-Signature=3e148feb268299e5f6475f0390778561b77b990b78176b69cc0dd32498a035c6&X-Amz-SignedHeaders=host&actor_id=0&repo_id=107595270&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-04-29 19:39:22--  https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200429%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200429T193922Z&X-Amz-Expires=300&X-Amz-Signature=3e148feb268299e5f6475f0390778561b77b990b78176b69cc0dd32498a035c6&X-Amz-SignedHeaders=host&actor_id=0&repo_id=107595270&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.30.36\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.30.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257557808 (246M) [application/octet-stream]\n",
            "Saving to: ‘/content/mask_rcnn_coco.h5.1’\n",
            "\n",
            "mask_rcnn_coco.h5.1 100%[===================>] 245.63M  31.1MB/s    in 23s     \n",
            "\n",
            "2020-04-29 19:39:45 (10.9 MB/s) - ‘/content/mask_rcnn_coco.h5.1’ saved [257557808/257557808]\n",
            "\n",
            "Archive:  /content/Cytometry-for-Google-Colab/Data.zip\n",
            "replace Data/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "/content/Cytometry-for-Google-Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:09:15.022782Z",
          "start_time": "2020-04-15T21:09:02.480621Z"
        },
        "id": "fWMgiLuZy8Np",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed556ae4-242e-4182-c356-805981f0c078"
      },
      "source": [
        "# Set matplotlib backend\n",
        "# This has to be done before other importa that might\n",
        "# set it, but only if we're running in script mode\n",
        "# rather than being imported.\n",
        "'''\n",
        "if __name__ == '__main__':\n",
        "    import matplotlib\n",
        "    # Agg backend runs without a display\n",
        "    matplotlib.use('Agg')\n",
        "    import matplotlib.pyplot as plt\n",
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import datetime\n",
        "import xlrd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "from imgaug import augmenters as iaa\n",
        "from libtiff import TIFF, TIFFfile\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Results directory\n",
        "# Save submission files here\n",
        "RESULTS_DIR = os.path.join(ROOT_DIR, \"results/cellcount/\")\n",
        "\n",
        "from MRCNN.config import Config\n",
        "import MRCNN.model as modellib\n",
        "from MRCNN import utils, visualize\n",
        "\n",
        "DataSize=100\n",
        "Validation_ratio=0.1\n",
        "Data_IDS=np.arange(1,DataSize+1,dtype=np.int16) \n",
        "VAL_IMAGE_IDS = np.random.choice(Data_IDS,size=np.int(Validation_ratio*DataSize),replace=False)\n",
        "VAL_IMAGE_IDS.sort()\n",
        "\n",
        "#####################################################\n",
        "#         Configuration\n",
        "#####################################################\n",
        "class CellCountConfig(Config):\n",
        "    NAME = 'CellCount'\n",
        "    \n",
        "    # Train on 1 GPU and 2 images per GPU.\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1 # Background + RedBloodCell\n",
        "    \n",
        "    # Don't exclude based on confidence. Since we have two classes\n",
        "    # then 0.5 is the minimum anyway as it picks between nucleus and BG\n",
        "    DETECTION_MIN_CONFIDENCE = 0\n",
        "    \n",
        "    # Backbone network architecture\n",
        "    # Supported values are: resnet50, resnet101\n",
        "    BACKBONE = \"resnet101\"\n",
        "    \n",
        "    # Input image resizing\n",
        "    IMAGE_RESIZE_MODE = \"pad64\"\n",
        "    IMAGE_MIN_DIM = 812\n",
        "    IMAGE_MAX_DIM = 1280\n",
        "    IMAGE_SHAPE= (832, 1280, 3)\n",
        "    \n",
        "    IMAGE_CHANNEL_COUNT = 3   \n",
        "    \n",
        "    # Length of square anchor side in pixels\n",
        "    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)\n",
        "    \n",
        "    # Number of ROIs per image to feed to classifier/mask heads\n",
        "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
        "    # enough positive proposals to fill this and keep a positive:negative\n",
        "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
        "    # the RPN NMS threshold.\n",
        "    TRAIN_ROIS_PER_IMAGE = 128\n",
        "\n",
        "    # Maximum number of ground truth instances to use in one image\n",
        "    MAX_GT_INSTANCES = 100\n",
        "\n",
        "    # Max number of final detections per image\n",
        "    DETECTION_MAX_INSTANCES = 200\n",
        "    \n",
        "    \n",
        "    # Use a small epoch since the data is simple\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    # use small validation steps since the epoch is small\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "    \n",
        "    # Non-max suppression threshold to filter RPN proposals.\n",
        "    # You can increase this during training to generate more propsals.\n",
        "    #RPN_NMS_THRESHOLD = 0.9\n",
        "    RPN_NMS_THRESHOLD=0.95\n",
        "    \n",
        "    # ROIs kept after non-maximum supression (training and inference)\n",
        "    POST_NMS_ROIS_TRAINING = 500\n",
        "    POST_NMS_ROIS_INFERENCE = 1000\n",
        "    \n",
        "    # Image mean (RGB)\n",
        "    MEAN_PIXEL = (126,126,126)\n",
        "        \n",
        "    # If enabled, resizes instance masks to a smaller size to reduce\n",
        "    # memory load. Recommended when using high-resolution images.\n",
        "    USE_MINI_MASK = True\n",
        "    #MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
        "    MINI_MASK_SHAPE = (100,100)\n",
        "\n",
        "    # Number of ROIs per image to feed to classifier/mask heads\n",
        "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
        "    # enough positive proposals to fill this and keep a positive:negative\n",
        "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
        "    # the RPN NMS threshold.\n",
        "    #TRAIN_ROIS_PER_IMAGE = 128\n",
        "    TRAIN_ROIS_PER_IMAGE = 256\n",
        "    \n",
        "\n",
        "#####################################################\n",
        "#         Dataset\n",
        "#####################################################\n",
        "class CellDataset(utils.Dataset):\n",
        "    \n",
        "    def Image_gen(self, FileName):\n",
        "        self.frame=0\n",
        "        self.ImgeFile=FileName\n",
        "        tif=TIFF.open(FileName)\n",
        "        for Image_gened in tif.iter_images():\n",
        "        #Image = imread(FileName,1)\n",
        "            self.frame+=1\n",
        "            yield Image_gened  \n",
        "    \n",
        "    def Image_getFrame(self, Image_dir, Frame):\n",
        "        #if self.ImgeFile!=Image_dir or self.frame > Frame:\n",
        "        Image_gen=self.Image_gen(Image_dir)\n",
        "        self.frame=0\n",
        "        im_getFrame=[]\n",
        "        while self.frame<Frame:\n",
        "            im_getFrame= next(Image_gen)\n",
        "        im_getFrame=np.array(im_getFrame)\n",
        "        return im_getFrame\n",
        "            \n",
        "    def load_cells(self, dataset_dir, subset):\n",
        "        \"\"\"\n",
        "        Load a subset of the cell dataset.\n",
        "        dataset_dir: Root directory of the dataset\n",
        "        subset: Subset to load. \n",
        "                * train: training data excluding validation images\n",
        "                * val: validation images from VAL_IMAGE_IDS\n",
        "        \"\"\"\n",
        "\n",
        "        # Add classes. We have one class.\n",
        "        # Naming the dataset Cells, and the 1st class RedBloodCell\n",
        "        self.add_class(\"Cells\", 1, \"RBC\")\n",
        "        ROOT_PATH=os.path.dirname(os.getcwd())\n",
        "        dataset_dir=os.path.join(ROOT_PATH,\"Data\",dataset_dir)\n",
        "       # Train or validation dataset?\n",
        "        assert subset in [\"train\", \"val\"]\n",
        "        if subset == \"val\":\n",
        "            image_ids = VAL_IMAGE_IDS\n",
        "        else:\n",
        "            # Get image ids from directory names\n",
        "            if subset == \"train\":\n",
        "                image_ids = list(set(Data_IDS) - set(VAL_IMAGE_IDS))\n",
        "        # Add images\n",
        "        for image_id in image_ids:\n",
        "            self.add_image(\n",
        "                \"Cells\",\n",
        "                image_id=image_id,\n",
        "                path=dataset_dir)\n",
        "                  \n",
        "    def load_image (self,image_id):\n",
        "        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
        "        \"\"\"\n",
        "        # Load image\n",
        "        info = self.image_info[image_id]\n",
        "        dataset_dir=info['path']\n",
        "        data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
        "        data=data.sheets()[0]\n",
        "        Image_dir=os.path.join(os.path.dirname(os.getcwd()),data.col_values(0)[1])\n",
        "        image=self.Image_getFrame(Image_dir, info['id'])\n",
        "        # If grayscale. Convert to RGB for consistency.\n",
        "        image=(image/np.max(image)*255).astype(np.float16)\n",
        "        if image.ndim != 3:\n",
        "            image = skimage.color.gray2rgb(image)\n",
        "        # If has an alpha channel, remove it for consistency\n",
        "        if image.shape[-1] == 4:\n",
        "            image = image[..., :3]\n",
        "        return image\n",
        "        \n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        dataset_dir=info['path']\n",
        "        data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
        "        data=data.sheets()[0]\n",
        "        Frame=data.col_values(1)[1:]\n",
        "        ClassName=data.col_values(2)[1:]\n",
        "        \n",
        "        MaskNum=data.col_values(4)[1:]\n",
        "        ImgMask = [(Class,ImgMask) for [Class,ImgMask,frame] in zip(ClassName, MaskNum,Frame) if frame==info['id']]\n",
        "        # Read mask files from .tif image\n",
        "        Mask=[]\n",
        "        ClassID=[]\n",
        "        for i,Img in enumerate(ImgMask):\n",
        "            # Get mask directory from image path\n",
        "            mask_dir = os.path.join(info['path'], \"{}.tif\".format(Img[1]))\n",
        "            #ID=[name['id'] for name in (self.class_info) if name.get('name')==Img[0]]\n",
        "            ID=1\n",
        "            im = cv2.imread(mask_dir,0).astype(np.bool)\n",
        "            Mask.append(im)\n",
        "            ClassID.append(ID)\n",
        "        Mask = np.stack(Mask, axis=-1)\n",
        "        ClassID= np.squeeze(np.array(ClassID))\n",
        "        return Mask,ClassID\n",
        "    \n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"cells\":\n",
        "            return info[\"id\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n",
        "\n",
        "############################################################\n",
        "#  Training\n",
        "############################################################\n",
        "\n",
        "def train(model, dataset_dir, subset):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    # Training dataset.\n",
        "    dataset_train = CellDataset()\n",
        "    dataset_train.load_cells(dataset_dir,\"train\")\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    # Validation dataset\n",
        "    dataset_val = CellDataset()\n",
        "    dataset_val.load_cells(dataset_dir, \"val\")\n",
        "    dataset_val.prepare()\n",
        "    \n",
        "    # Image augmentation\n",
        "    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n",
        "    augmentation = iaa.SomeOf((0, 2), [\n",
        "        iaa.Fliplr(0.5),\n",
        "        iaa.Flipud(0.5),\n",
        "        iaa.OneOf([iaa.Affine(rotate=90),\n",
        "                   iaa.Affine(rotate=180),\n",
        "                   iaa.Affine(rotate=270)]),\n",
        "        iaa.Multiply((0.8, 1.5)),\n",
        "        iaa.GaussianBlur(sigma=(0.0, 5.0))\n",
        "    ])\n",
        "\n",
        "    # If starting from imagenet, train heads only for a bit\n",
        "    # since they have random weights\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                augmentation=augmentation,\n",
        "                epochs=15,\n",
        "                layers='4+')\n",
        "    '''\n",
        "    print(\"Train all layers\")\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=40,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n",
        "    '''"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:22:53.550849Z",
          "start_time": "2020-04-15T21:09:22.980050Z"
        },
        "scrolled": false,
        "id": "17HIwHsny8Ny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c0acbf2-765b-4562-ec75-f6ce47ee0b86"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
        "    config = CellCountConfig()\n",
        "    #config.display()\n",
        "\n",
        "    # Create model\n",
        "    model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=RESULTS_DIR)\n",
        "\n",
        "    #Load COCO weights\n",
        "    COCO_WEIGHTS_PATH = os.path.join(os.path.dirname(ROOT_DIR), \"mask_rcnn_coco.h5\")\n",
        "    weights_path = COCO_WEIGHTS_PATH\n",
        "\n",
        "    #weights_path = model.get_imagenet_weights()\n",
        "\n",
        "    # Load weights\n",
        "    model.load_weights(weights_path, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "    #model.load_weights(weights_path, by_name=True)\n",
        "    train(model=model, dataset_dir='val', subset='train')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/utils.py:198: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /content/Cytometry-for-Google-Colab/results/cellcount/cellcount20200429T1940/mask_rcnn_cellcount_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "res4a_branch2a         (Conv2D)\n",
            "bn4a_branch2a          (BatchNorm)\n",
            "res4a_branch2b         (Conv2D)\n",
            "bn4a_branch2b          (BatchNorm)\n",
            "res4a_branch2c         (Conv2D)\n",
            "res4a_branch1          (Conv2D)\n",
            "bn4a_branch2c          (BatchNorm)\n",
            "bn4a_branch1           (BatchNorm)\n",
            "res4b_branch2a         (Conv2D)\n",
            "bn4b_branch2a          (BatchNorm)\n",
            "res4b_branch2b         (Conv2D)\n",
            "bn4b_branch2b          (BatchNorm)\n",
            "res4b_branch2c         (Conv2D)\n",
            "bn4b_branch2c          (BatchNorm)\n",
            "res4c_branch2a         (Conv2D)\n",
            "bn4c_branch2a          (BatchNorm)\n",
            "res4c_branch2b         (Conv2D)\n",
            "bn4c_branch2b          (BatchNorm)\n",
            "res4c_branch2c         (Conv2D)\n",
            "bn4c_branch2c          (BatchNorm)\n",
            "res4d_branch2a         (Conv2D)\n",
            "bn4d_branch2a          (BatchNorm)\n",
            "res4d_branch2b         (Conv2D)\n",
            "bn4d_branch2b          (BatchNorm)\n",
            "res4d_branch2c         (Conv2D)\n",
            "bn4d_branch2c          (BatchNorm)\n",
            "res4e_branch2a         (Conv2D)\n",
            "bn4e_branch2a          (BatchNorm)\n",
            "res4e_branch2b         (Conv2D)\n",
            "bn4e_branch2b          (BatchNorm)\n",
            "res4e_branch2c         (Conv2D)\n",
            "bn4e_branch2c          (BatchNorm)\n",
            "res4f_branch2a         (Conv2D)\n",
            "bn4f_branch2a          (BatchNorm)\n",
            "res4f_branch2b         (Conv2D)\n",
            "bn4f_branch2b          (BatchNorm)\n",
            "res4f_branch2c         (Conv2D)\n",
            "bn4f_branch2c          (BatchNorm)\n",
            "res4g_branch2a         (Conv2D)\n",
            "bn4g_branch2a          (BatchNorm)\n",
            "res4g_branch2b         (Conv2D)\n",
            "bn4g_branch2b          (BatchNorm)\n",
            "res4g_branch2c         (Conv2D)\n",
            "bn4g_branch2c          (BatchNorm)\n",
            "res4h_branch2a         (Conv2D)\n",
            "bn4h_branch2a          (BatchNorm)\n",
            "res4h_branch2b         (Conv2D)\n",
            "bn4h_branch2b          (BatchNorm)\n",
            "res4h_branch2c         (Conv2D)\n",
            "bn4h_branch2c          (BatchNorm)\n",
            "res4i_branch2a         (Conv2D)\n",
            "bn4i_branch2a          (BatchNorm)\n",
            "res4i_branch2b         (Conv2D)\n",
            "bn4i_branch2b          (BatchNorm)\n",
            "res4i_branch2c         (Conv2D)\n",
            "bn4i_branch2c          (BatchNorm)\n",
            "res4j_branch2a         (Conv2D)\n",
            "bn4j_branch2a          (BatchNorm)\n",
            "res4j_branch2b         (Conv2D)\n",
            "bn4j_branch2b          (BatchNorm)\n",
            "res4j_branch2c         (Conv2D)\n",
            "bn4j_branch2c          (BatchNorm)\n",
            "res4k_branch2a         (Conv2D)\n",
            "bn4k_branch2a          (BatchNorm)\n",
            "res4k_branch2b         (Conv2D)\n",
            "bn4k_branch2b          (BatchNorm)\n",
            "res4k_branch2c         (Conv2D)\n",
            "bn4k_branch2c          (BatchNorm)\n",
            "res4l_branch2a         (Conv2D)\n",
            "bn4l_branch2a          (BatchNorm)\n",
            "res4l_branch2b         (Conv2D)\n",
            "bn4l_branch2b          (BatchNorm)\n",
            "res4l_branch2c         (Conv2D)\n",
            "bn4l_branch2c          (BatchNorm)\n",
            "res4m_branch2a         (Conv2D)\n",
            "bn4m_branch2a          (BatchNorm)\n",
            "res4m_branch2b         (Conv2D)\n",
            "bn4m_branch2b          (BatchNorm)\n",
            "res4m_branch2c         (Conv2D)\n",
            "bn4m_branch2c          (BatchNorm)\n",
            "res4n_branch2a         (Conv2D)\n",
            "bn4n_branch2a          (BatchNorm)\n",
            "res4n_branch2b         (Conv2D)\n",
            "bn4n_branch2b          (BatchNorm)\n",
            "res4n_branch2c         (Conv2D)\n",
            "bn4n_branch2c          (BatchNorm)\n",
            "res4o_branch2a         (Conv2D)\n",
            "bn4o_branch2a          (BatchNorm)\n",
            "res4o_branch2b         (Conv2D)\n",
            "bn4o_branch2b          (BatchNorm)\n",
            "res4o_branch2c         (Conv2D)\n",
            "bn4o_branch2c          (BatchNorm)\n",
            "res4p_branch2a         (Conv2D)\n",
            "bn4p_branch2a          (BatchNorm)\n",
            "res4p_branch2b         (Conv2D)\n",
            "bn4p_branch2b          (BatchNorm)\n",
            "res4p_branch2c         (Conv2D)\n",
            "bn4p_branch2c          (BatchNorm)\n",
            "res4q_branch2a         (Conv2D)\n",
            "bn4q_branch2a          (BatchNorm)\n",
            "res4q_branch2b         (Conv2D)\n",
            "bn4q_branch2b          (BatchNorm)\n",
            "res4q_branch2c         (Conv2D)\n",
            "bn4q_branch2c          (BatchNorm)\n",
            "res4r_branch2a         (Conv2D)\n",
            "bn4r_branch2a          (BatchNorm)\n",
            "res4r_branch2b         (Conv2D)\n",
            "bn4r_branch2b          (BatchNorm)\n",
            "res4r_branch2c         (Conv2D)\n",
            "bn4r_branch2c          (BatchNorm)\n",
            "res4s_branch2a         (Conv2D)\n",
            "bn4s_branch2a          (BatchNorm)\n",
            "res4s_branch2b         (Conv2D)\n",
            "bn4s_branch2b          (BatchNorm)\n",
            "res4s_branch2c         (Conv2D)\n",
            "bn4s_branch2c          (BatchNorm)\n",
            "res4t_branch2a         (Conv2D)\n",
            "bn4t_branch2a          (BatchNorm)\n",
            "res4t_branch2b         (Conv2D)\n",
            "bn4t_branch2b          (BatchNorm)\n",
            "res4t_branch2c         (Conv2D)\n",
            "bn4t_branch2c          (BatchNorm)\n",
            "res4u_branch2a         (Conv2D)\n",
            "bn4u_branch2a          (BatchNorm)\n",
            "res4u_branch2b         (Conv2D)\n",
            "bn4u_branch2b          (BatchNorm)\n",
            "res4u_branch2c         (Conv2D)\n",
            "bn4u_branch2c          (BatchNorm)\n",
            "res4v_branch2a         (Conv2D)\n",
            "bn4v_branch2a          (BatchNorm)\n",
            "res4v_branch2b         (Conv2D)\n",
            "bn4v_branch2b          (BatchNorm)\n",
            "res4v_branch2c         (Conv2D)\n",
            "bn4v_branch2c          (BatchNorm)\n",
            "res4w_branch2a         (Conv2D)\n",
            "bn4w_branch2a          (BatchNorm)\n",
            "res4w_branch2b         (Conv2D)\n",
            "bn4w_branch2b          (BatchNorm)\n",
            "res4w_branch2c         (Conv2D)\n",
            "bn4w_branch2c          (BatchNorm)\n",
            "res5a_branch2a         (Conv2D)\n",
            "bn5a_branch2a          (BatchNorm)\n",
            "res5a_branch2b         (Conv2D)\n",
            "bn5a_branch2b          (BatchNorm)\n",
            "res5a_branch2c         (Conv2D)\n",
            "res5a_branch1          (Conv2D)\n",
            "bn5a_branch2c          (BatchNorm)\n",
            "bn5a_branch1           (BatchNorm)\n",
            "res5b_branch2a         (Conv2D)\n",
            "bn5b_branch2a          (BatchNorm)\n",
            "res5b_branch2b         (Conv2D)\n",
            "bn5b_branch2b          (BatchNorm)\n",
            "res5b_branch2c         (Conv2D)\n",
            "bn5b_branch2c          (BatchNorm)\n",
            "res5c_branch2a         (Conv2D)\n",
            "bn5c_branch2a          (BatchNorm)\n",
            "res5c_branch2b         (Conv2D)\n",
            "bn5c_branch2b          (BatchNorm)\n",
            "res5c_branch2c         (Conv2D)\n",
            "bn5c_branch2c          (BatchNorm)\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
            "ERROR:root:Error processing image {'id': 96, 'source': 'Cells', 'path': '/content/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1263, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: too many indices for array\n",
            "ERROR:root:Error processing image {'id': 96, 'source': 'Cells', 'path': '/content/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1263, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: too many indices for array\n",
            "ERROR:root:Error processing image {'id': 96, 'source': 'Cells', 'path': '/content/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1263, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: too many indices for array\n",
            "ERROR:root:Error processing image {'id': 96, 'source': 'Cells', 'path': '/content/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1263, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: too many indices for array\n",
            "ERROR:root:Error processing image {'id': 96, 'source': 'Cells', 'path': '/content/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1263, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: too many indices for array\n",
            "ERROR:root:Error processing image {'id': 96, 'source': 'Cells', 'path': '/content/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1263, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: too many indices for array\n",
            "ERROR:root:Error processing image {'id': 96, 'source': 'Cells', 'path': '/content/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1263, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: too many indices for array\n",
            "ERROR:root:Error processing image {'id': 96, 'source': 'Cells', 'path': '/content/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1263, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: too many indices for array\n",
            "ERROR:root:Error processing image {'id': 96, 'source': 'Cells', 'path': '/content/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1263, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: too many indices for array\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.0211"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Error processing image {'id': 96, 'source': 'Cells', 'path': '/content/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1263, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: too many indices for array\n",
            "ERROR:root:Error processing image {'id': 96, 'source': 'Cells', 'path': '/content/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1263, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: too many indices for array\n",
            "ERROR:root:Error processing image {'id': 96, 'source': 'Cells', 'path': '/content/Data/val'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1707, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\", line 1263, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: too many indices for array\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 72s 718ms/step - loss: 2.0138 - val_loss: 2.2541\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/15\n",
            " 73/100 [====================>.........] - ETA: 11s - loss: 1.5866"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:26:24.856692Z",
          "start_time": "2020-04-15T21:26:11.833656Z"
        },
        "id": "rlgYbX73y8N3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################\n",
        "#  Detection\n",
        "############################################################\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
        "config = CellCountConfig()\n",
        "\n",
        "#Create Model\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=RESULTS_DIR)\n",
        "\n",
        "#Load weights\n",
        "weights_path= \"results/cellcount/cellcount20200129T0945/mask_rcnn_cellcount_0015.h5\"\n",
        "# Load weights\n",
        "model.load_weights(weights_path, by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:30:39.947165Z",
          "start_time": "2020-04-15T21:30:13.315439Z"
        },
        "id": "Guz4JPA6y8N8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read dataset\n",
        "dataset = CellDataset()\n",
        "dataset.load_cells('val', 'train')\n",
        "dataset.prepare()\n",
        "\n",
        "GT_no=[]\n",
        "DE_no=[]\n",
        "for image_id in range (1,28):\n",
        "    # Load image and run detection\n",
        "    image = dataset.load_image(image_id)\n",
        "    mask,class_id= dataset.load_mask(image_id)\n",
        "    # Detect objects\n",
        "    r = model.detect([image], verbose=0)[0]\n",
        "    # Encode image to RLE. Returns a string of multiple lines\n",
        "    source_id = dataset.image_info[image_id][\"id\"]\n",
        "    #rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
        "    #submission.append(rle)\n",
        "    GT_no.append(np.size(mask,2))\n",
        "    DE_no.append(len(r['class_ids']))\n",
        "    print('--------------------------------')\n",
        "    print('Frame ID =', dataset.image_info[image_id][\"id\"])\n",
        "    print('Ground Truth Cell Number = ', GT_no[-1])\n",
        "    print('Detected Cell Number =', DE_no[-1])\n",
        "    visualize.display_instances(\n",
        "        np.sum(mask,axis=2), r['rois'], r['masks'], r['class_ids'],\n",
        "        dataset.class_names, r['scores'],\n",
        "        show_bbox=False, show_mask=False,\n",
        "        title=\"Predictions\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "GkVJoLK-y8OD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read dataset\n",
        "dataset = CellDataset()\n",
        "dataset.load_cells('val', 'train')\n",
        "dataset.prepare()\n",
        "im_dir='../GFC_505nm_40X1p15NA_PCO_500usexp_160fps_3@0001.tif'\n",
        "image =dataset.Image_getFrame(im_dir,27)\n",
        "if image.ndim != 3:\n",
        "    image = skimage.color.gray2rgb(image)\n",
        "# If has an alpha channel, remove it for consistency\n",
        "if image.shape[-1] == 4:\n",
        "    image = image[..., :3]\n",
        "image=(image/np.max(image)*255).astype(np.float16)\n",
        "# Detect objects\n",
        "r = model.detect([image], verbose=0)[0]\n",
        "# Encode image to RLE. Returns a string of multiple lines\n",
        "source_id = dataset.image_info[image_id][\"id\"]\n",
        "#rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
        "#submission.append(rle)\n",
        "GT_no.append(np.size(mask,2))\n",
        "DE_no.append(len(r['class_ids']))\n",
        "print('--------------------------------')\n",
        "print('Frame ID =', dataset.image_info[image_id][\"id\"])\n",
        "print('Ground Truth Cell Number = ', GT_no[-1])\n",
        "print('Detected Cell Number =', DE_no[-1])\n",
        "#bg=np.zeros(np.shape(image))\n",
        "visualize.display_instances(\n",
        "    image, r['rois'], r['masks'], r['class_ids'],\n",
        "    dataset.class_names, r['scores'],\n",
        "    show_bbox=False, show_mask=False,\n",
        "    title=\"Predictions\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqm6YUJgy8OK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhc6VQnFy8OP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E84KD59y8OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################\n",
        "#  Detection\n",
        "############################################################\n",
        "\n",
        "def detect(model, dataset_dir, subset):\n",
        "    \"\"\"Run detection on images in the given directory.\"\"\"\n",
        "    print(\"Running on {}\".format(dataset_dir))\n",
        "\n",
        "    # Create directory\n",
        "    if not os.path.exists(RESULTS_DIR):\n",
        "        os.makedirs(RESULTS_DIR)\n",
        "    submit_dir = \"submit_{:%Y%m%dT%H%M%S}\".format(datetime.datetime.now())\n",
        "    submit_dir = os.path.join(RESULTS_DIR, submit_dir)\n",
        "    os.makedirs(submit_dir)\n",
        "\n",
        "    # Read dataset\n",
        "    dataset = CellDataset()\n",
        "    dataset.load_cells(dataset_dir, subset)\n",
        "    dataset.prepare()\n",
        "    # Load over images\n",
        "    submission = []\n",
        "    for image_id in dataset.image_ids:\n",
        "        # Load image and run detection\n",
        "        image = dataset.load_image(image_id)\n",
        "        # Detect objects\n",
        "        r = model.detect([image], verbose=0)[0]\n",
        "        # Encode image to RLE. Returns a string of multiple lines\n",
        "        source_id = dataset.image_info[image_id][\"id\"]\n",
        "        rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
        "        submission.append(rle)\n",
        "        # Save image with masks\n",
        "        visualize.display_instances(\n",
        "            image, r['rois'], r['masks'], r['class_ids'],\n",
        "            dataset.class_names, r['scores'],\n",
        "            show_bbox=False, show_mask=False,\n",
        "            title=\"Predictions\")\n",
        "        plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))\n",
        "\n",
        "    # Save to csv file\n",
        "    submission = \"ImageId,EncodedPixels\\n\" + \"\\n\".join(submission)\n",
        "    file_path = os.path.join(submit_dir, \"submit.csv\")\n",
        "    with open(file_path, \"w\") as f:\n",
        "        f.write(submission)\n",
        "    print(\"Saved to \", submit_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf-Dlmoly8OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.max(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHXCLCily8Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}