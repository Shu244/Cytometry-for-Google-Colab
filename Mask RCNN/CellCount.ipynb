{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "CellCount.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVH-tWxvGpWg",
        "colab_type": "text"
      },
      "source": [
        "## Set up\n",
        "\n",
        "Please obtain the raw data zip file and add it to your Google drive. Update line 29 of cell 1 to specify the path for where this data zip file is. \n",
        "\n",
        "The first cell configures the Google Colab environment to allow the repo to execute properly. Simply \"Run All\" to get started."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42XoC_v9FRNC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b837d1a7-409d-449e-beac-ef1eb675dba9"
      },
      "source": [
        "# Getting raw data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip '/content/drive/My Drive/JHU/2020 Spring Semester/Machine Learning: Deep Learning/Final Project/raw image.zip' -d /content/\n",
        "\n",
        "# Organizing raw data\n",
        "import os\n",
        "from shutil import move\n",
        "\n",
        "root = '/content/'\n",
        "for filename in os.listdir(os.path.join(root, 'raw image')):\n",
        "    move(os.path.join(root, 'raw image', filename), os.path.join(root, filename))\n",
        "\n",
        "# Necessary installs to get code working on Google colab\n",
        "!pip install libtiff\n",
        "\n",
        "# Cloning core repo\n",
        "!git clone https://github.com/Shu244/Cytometry-for-Google-Colab.git\n",
        "\n",
        "# Updating environment variables\n",
        "import sys\n",
        "sys.path.append(\"/content/Cytometry-for-Google-Colab/Mask RCNN\")\n",
        "\n",
        "# Downgrading Tensorflow version\n",
        "!pip install tensorflow-gpu==1.15.0\n",
        "!pip install tensorflow==1.15.0\n",
        "\n",
        "import tensorflow as tf\n",
        "assert (tf.__version__ == \"1.15.0\"), \"Restart runtime to use newly installed Tensorflow\"\n",
        "\n",
        "# Download pretrained COCO parameters\n",
        "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5 -P /content/\n",
        "\n",
        "# Unzip data\n",
        "!unzip /content/Cytometry-for-Google-Colab/Data.zip\n",
        "\n",
        "# Change into /content/ directory\n",
        "%cd /content/Cytometry-for-Google-Colab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Archive:  /content/drive/My Drive/JHU/2020 Spring Semester/Machine Learning: Deep Learning/Final Project/raw image.zip\n",
            "   creating: /content/raw image/\n",
            "  inflating: /content/raw image/GFC_505nm_40X1p15NA_PCO_500usexp_160fps_3.tif  \n",
            "   creating: /content/__MACOSX/\n",
            "   creating: /content/__MACOSX/raw image/\n",
            "  inflating: /content/__MACOSX/raw image/._GFC_505nm_40X1p15NA_PCO_500usexp_160fps_3.tif  \n",
            "  inflating: /content/raw image/GFC_505nm_40X1p15NA_PCO_500usexp_160fps_3@0001.tif  \n",
            "  inflating: /content/__MACOSX/raw image/._GFC_505nm_40X1p15NA_PCO_500usexp_160fps_3@0001.tif  \n",
            "Collecting libtiff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/8f/b844284d43d385c08967b25eb76f625a5f06490cc4680e17644587053756/libtiff-0.4.2.tar.gz (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 4.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: libtiff\n",
            "  Building wheel for libtiff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libtiff: filename=libtiff-0.4.2-cp36-cp36m-linux_x86_64.whl size=280192 sha256=d5613358420911529340481d16f9d384c75ae3ffda33945ff543ab32090fbc58\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/ce/79/9c7115224f798f73bdbd2c23e06c6fa048adcca7041b9fd104\n",
            "Successfully built libtiff\n",
            "Installing collected packages: libtiff\n",
            "Successfully installed libtiff-0.4.2\n",
            "Cloning into 'Cytometry-for-Google-Colab'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 43 (delta 6), reused 26 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (43/43), done.\n",
            "Collecting tensorflow-gpu==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.12.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 41.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.18.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.28.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.12.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 34.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (46.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (2.10.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=36e41e1de183244ab9fcfb912598ebef210424328f05a2fd97faae41b60f3668\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorflow-estimator<2.3.0,>=2.2.0rc0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, gast, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:09:15.022782Z",
          "start_time": "2020-04-15T21:09:02.480621Z"
        },
        "id": "fWMgiLuZy8Np",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set matplotlib backend\n",
        "# This has to be done before other importa that might\n",
        "# set it, but only if we're running in script mode\n",
        "# rather than being imported.\n",
        "'''\n",
        "if __name__ == '__main__':\n",
        "    import matplotlib\n",
        "    # Agg backend runs without a display\n",
        "    matplotlib.use('Agg')\n",
        "    import matplotlib.pyplot as plt\n",
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import datetime\n",
        "import xlrd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "from imgaug import augmenters as iaa\n",
        "from libtiff import TIFF, TIFFfile\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Results directory\n",
        "# Save submission files here\n",
        "RESULTS_DIR = os.path.join(ROOT_DIR, \"results/cellcount/\")\n",
        "\n",
        "from MRCNN.config import Config\n",
        "import MRCNN.model as modellib\n",
        "from MRCNN import utils, visualize\n",
        "\n",
        "DataSize=100\n",
        "Validation_ratio=0.1\n",
        "Data_IDS=np.arange(1,DataSize+1,dtype=np.int16) \n",
        "VAL_IMAGE_IDS = np.random.choice(Data_IDS,size=np.int(Validation_ratio*DataSize),replace=False)\n",
        "VAL_IMAGE_IDS.sort()\n",
        "\n",
        "#####################################################\n",
        "#         Configuration\n",
        "#####################################################\n",
        "class CellCountConfig(Config):\n",
        "    NAME = 'CellCount'\n",
        "    \n",
        "    # Train on 1 GPU and 2 images per GPU.\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1 # Background + RedBloodCell\n",
        "    \n",
        "    # Don't exclude based on confidence. Since we have two classes\n",
        "    # then 0.5 is the minimum anyway as it picks between nucleus and BG\n",
        "    DETECTION_MIN_CONFIDENCE = 0\n",
        "    \n",
        "    # Backbone network architecture\n",
        "    # Supported values are: resnet50, resnet101\n",
        "    BACKBONE = \"resnet101\"\n",
        "    \n",
        "    # Input image resizing\n",
        "    IMAGE_RESIZE_MODE = \"pad64\"\n",
        "    IMAGE_MIN_DIM = 812\n",
        "    IMAGE_MAX_DIM = 1280\n",
        "    IMAGE_SHAPE= (832, 1280, 3)\n",
        "    \n",
        "    IMAGE_CHANNEL_COUNT = 3   \n",
        "    \n",
        "    # Length of square anchor side in pixels\n",
        "    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)\n",
        "    \n",
        "    # Number of ROIs per image to feed to classifier/mask heads\n",
        "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
        "    # enough positive proposals to fill this and keep a positive:negative\n",
        "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
        "    # the RPN NMS threshold.\n",
        "    TRAIN_ROIS_PER_IMAGE = 128\n",
        "\n",
        "    # Maximum number of ground truth instances to use in one image\n",
        "    MAX_GT_INSTANCES = 100\n",
        "\n",
        "    # Max number of final detections per image\n",
        "    DETECTION_MAX_INSTANCES = 200\n",
        "    \n",
        "    \n",
        "    # Use a small epoch since the data is simple\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    # use small validation steps since the epoch is small\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "    \n",
        "    # Non-max suppression threshold to filter RPN proposals.\n",
        "    # You can increase this during training to generate more propsals.\n",
        "    #RPN_NMS_THRESHOLD = 0.9\n",
        "    RPN_NMS_THRESHOLD=0.95\n",
        "    \n",
        "    # ROIs kept after non-maximum supression (training and inference)\n",
        "    POST_NMS_ROIS_TRAINING = 500\n",
        "    POST_NMS_ROIS_INFERENCE = 1000\n",
        "    \n",
        "    # Image mean (RGB)\n",
        "    MEAN_PIXEL = (126,126,126)\n",
        "        \n",
        "    # If enabled, resizes instance masks to a smaller size to reduce\n",
        "    # memory load. Recommended when using high-resolution images.\n",
        "    USE_MINI_MASK = True\n",
        "    #MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
        "    MINI_MASK_SHAPE = (100,100)\n",
        "\n",
        "    # Number of ROIs per image to feed to classifier/mask heads\n",
        "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
        "    # enough positive proposals to fill this and keep a positive:negative\n",
        "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
        "    # the RPN NMS threshold.\n",
        "    #TRAIN_ROIS_PER_IMAGE = 128\n",
        "    TRAIN_ROIS_PER_IMAGE = 256\n",
        "    \n",
        "\n",
        "#####################################################\n",
        "#         Dataset\n",
        "#####################################################\n",
        "class CellDataset(utils.Dataset):\n",
        "    \n",
        "    def Image_gen(self, FileName):\n",
        "        self.frame=0\n",
        "        self.ImgeFile=FileName\n",
        "        tif=TIFF.open(FileName)\n",
        "        for Image_gened in tif.iter_images():\n",
        "        #Image = imread(FileName,1)\n",
        "            self.frame+=1\n",
        "            yield Image_gened  \n",
        "    \n",
        "    def Image_getFrame(self, Image_dir, Frame):\n",
        "        #if self.ImgeFile!=Image_dir or self.frame > Frame:\n",
        "        Image_gen=self.Image_gen(Image_dir)\n",
        "        self.frame=0\n",
        "        im_getFrame=[]\n",
        "        while self.frame<Frame:\n",
        "            im_getFrame= next(Image_gen)\n",
        "        im_getFrame=np.array(im_getFrame)\n",
        "        return im_getFrame\n",
        "            \n",
        "    def load_cells(self, dataset_dir, subset):\n",
        "        \"\"\"\n",
        "        Load a subset of the cell dataset.\n",
        "        dataset_dir: Root directory of the dataset\n",
        "        subset: Subset to load. \n",
        "                * train: training data excluding validation images\n",
        "                * val: validation images from VAL_IMAGE_IDS\n",
        "        \"\"\"\n",
        "\n",
        "        # Add classes. We have one class.\n",
        "        # Naming the dataset Cells, and the 1st class RedBloodCell\n",
        "        self.add_class(\"Cells\", 1, \"RBC\")\n",
        "        ROOT_PATH=os.path.dirname(os.getcwd())\n",
        "        dataset_dir=os.path.join(ROOT_PATH,\"Data\",dataset_dir)\n",
        "       # Train or validation dataset?\n",
        "        assert subset in [\"train\", \"val\"]\n",
        "        if subset == \"val\":\n",
        "            image_ids = VAL_IMAGE_IDS\n",
        "        else:\n",
        "            # Get image ids from directory names\n",
        "            if subset == \"train\":\n",
        "                image_ids = list(set(Data_IDS) - set(VAL_IMAGE_IDS))\n",
        "        # Add images\n",
        "        for image_id in image_ids:\n",
        "            self.add_image(\n",
        "                \"Cells\",\n",
        "                image_id=image_id,\n",
        "                path=dataset_dir)\n",
        "                  \n",
        "    def load_image (self,image_id):\n",
        "        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
        "        \"\"\"\n",
        "        # Load image\n",
        "        info = self.image_info[image_id]\n",
        "        dataset_dir=info['path']\n",
        "        data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
        "        data=data.sheets()[0]\n",
        "        Image_dir=os.path.join(os.path.dirname(os.getcwd()),data.col_values(0)[1])\n",
        "        image=self.Image_getFrame(Image_dir, info['id'])\n",
        "        # If grayscale. Convert to RGB for consistency.\n",
        "        image=(image/np.max(image)*255).astype(np.float16)\n",
        "        if image.ndim != 3:\n",
        "            image = skimage.color.gray2rgb(image)\n",
        "        # If has an alpha channel, remove it for consistency\n",
        "        if image.shape[-1] == 4:\n",
        "            image = image[..., :3]\n",
        "        return image\n",
        "        \n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        dataset_dir=info['path']\n",
        "        data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
        "        data=data.sheets()[0]\n",
        "        Frame=data.col_values(1)[1:]\n",
        "        ClassName=data.col_values(2)[1:]\n",
        "        \n",
        "        MaskNum=data.col_values(4)[1:]\n",
        "        ImgMask = [(Class,ImgMask) for [Class,ImgMask,frame] in zip(ClassName, MaskNum,Frame) if frame==info['id']]\n",
        "        # Read mask files from .tif image\n",
        "        Mask=[]\n",
        "        ClassID=[]\n",
        "        for i,Img in enumerate(ImgMask):\n",
        "            # Get mask directory from image path\n",
        "            mask_dir = os.path.join(info['path'], \"{}.tif\".format(Img[1]))\n",
        "            #ID=[name['id'] for name in (self.class_info) if name.get('name')==Img[0]]\n",
        "            ID=1\n",
        "            im = cv2.imread(mask_dir,0).astype(np.bool)\n",
        "            Mask.append(im)\n",
        "            ClassID.append(ID)\n",
        "        Mask = np.stack(Mask, axis=-1)\n",
        "        ClassID= np.squeeze(np.array(ClassID))\n",
        "        return Mask,ClassID\n",
        "    \n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"cells\":\n",
        "            return info[\"id\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n",
        "\n",
        "############################################################\n",
        "#  Training\n",
        "############################################################\n",
        "\n",
        "def train(model, dataset_dir, subset):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    # Training dataset.\n",
        "    dataset_train = CellDataset()\n",
        "    dataset_train.load_cells(dataset_dir,\"train\")\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    # Validation dataset\n",
        "    dataset_val = CellDataset()\n",
        "    dataset_val.load_cells(dataset_dir, \"val\")\n",
        "    dataset_val.prepare()\n",
        "    \n",
        "    # Image augmentation\n",
        "    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n",
        "    augmentation = iaa.SomeOf((0, 2), [\n",
        "        iaa.Fliplr(0.5),\n",
        "        iaa.Flipud(0.5),\n",
        "        iaa.OneOf([iaa.Affine(rotate=90),\n",
        "                   iaa.Affine(rotate=180),\n",
        "                   iaa.Affine(rotate=270)]),\n",
        "        iaa.Multiply((0.8, 1.5)),\n",
        "        iaa.GaussianBlur(sigma=(0.0, 5.0))\n",
        "    ])\n",
        "\n",
        "    # If starting from imagenet, train heads only for a bit\n",
        "    # since they have random weights\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                augmentation=augmentation,\n",
        "                epochs=15,\n",
        "                layers='4+')\n",
        "    '''\n",
        "    print(\"Train all layers\")\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=40,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n",
        "    '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:22:53.550849Z",
          "start_time": "2020-04-15T21:09:22.980050Z"
        },
        "scrolled": false,
        "id": "17HIwHsny8Ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
        "    config = CellCountConfig()\n",
        "    #config.display()\n",
        "\n",
        "    # Create model\n",
        "    model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=RESULTS_DIR)\n",
        "\n",
        "    #Load COCO weights\n",
        "    COCO_WEIGHTS_PATH = os.path.join(os.path.dirname(ROOT_DIR), \"mask_rcnn_coco.h5\")\n",
        "    weights_path = COCO_WEIGHTS_PATH\n",
        "\n",
        "    #weights_path = model.get_imagenet_weights()\n",
        "\n",
        "    # Load weights\n",
        "    model.load_weights(weights_path, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "    #model.load_weights(weights_path, by_name=True)\n",
        "    train(model=model, dataset_dir='val', subset='train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:26:24.856692Z",
          "start_time": "2020-04-15T21:26:11.833656Z"
        },
        "id": "rlgYbX73y8N3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################\n",
        "#  Detection\n",
        "############################################################\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
        "config = CellCountConfig()\n",
        "\n",
        "#Create Model\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=RESULTS_DIR)\n",
        "\n",
        "#Load weights\n",
        "weights_path= \"results/cellcount/cellcount20200129T0945/mask_rcnn_cellcount_0015.h5\"\n",
        "# Load weights\n",
        "model.load_weights(weights_path, by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:30:39.947165Z",
          "start_time": "2020-04-15T21:30:13.315439Z"
        },
        "id": "Guz4JPA6y8N8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read dataset\n",
        "dataset = CellDataset()\n",
        "dataset.load_cells('val', 'train')\n",
        "dataset.prepare()\n",
        "\n",
        "GT_no=[]\n",
        "DE_no=[]\n",
        "for image_id in range (1,28):\n",
        "    # Load image and run detection\n",
        "    image = dataset.load_image(image_id)\n",
        "    mask,class_id= dataset.load_mask(image_id)\n",
        "    # Detect objects\n",
        "    r = model.detect([image], verbose=0)[0]\n",
        "    # Encode image to RLE. Returns a string of multiple lines\n",
        "    source_id = dataset.image_info[image_id][\"id\"]\n",
        "    #rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
        "    #submission.append(rle)\n",
        "    GT_no.append(np.size(mask,2))\n",
        "    DE_no.append(len(r['class_ids']))\n",
        "    print('--------------------------------')\n",
        "    print('Frame ID =', dataset.image_info[image_id][\"id\"])\n",
        "    print('Ground Truth Cell Number = ', GT_no[-1])\n",
        "    print('Detected Cell Number =', DE_no[-1])\n",
        "    visualize.display_instances(\n",
        "        np.sum(mask,axis=2), r['rois'], r['masks'], r['class_ids'],\n",
        "        dataset.class_names, r['scores'],\n",
        "        show_bbox=False, show_mask=False,\n",
        "        title=\"Predictions\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "GkVJoLK-y8OD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read dataset\n",
        "dataset = CellDataset()\n",
        "dataset.load_cells('val', 'train')\n",
        "dataset.prepare()\n",
        "im_dir='../GFC_505nm_40X1p15NA_PCO_500usexp_160fps_3@0001.tif'\n",
        "image =dataset.Image_getFrame(im_dir,27)\n",
        "if image.ndim != 3:\n",
        "    image = skimage.color.gray2rgb(image)\n",
        "# If has an alpha channel, remove it for consistency\n",
        "if image.shape[-1] == 4:\n",
        "    image = image[..., :3]\n",
        "image=(image/np.max(image)*255).astype(np.float16)\n",
        "# Detect objects\n",
        "r = model.detect([image], verbose=0)[0]\n",
        "# Encode image to RLE. Returns a string of multiple lines\n",
        "source_id = dataset.image_info[image_id][\"id\"]\n",
        "#rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
        "#submission.append(rle)\n",
        "GT_no.append(np.size(mask,2))\n",
        "DE_no.append(len(r['class_ids']))\n",
        "print('--------------------------------')\n",
        "print('Frame ID =', dataset.image_info[image_id][\"id\"])\n",
        "print('Ground Truth Cell Number = ', GT_no[-1])\n",
        "print('Detected Cell Number =', DE_no[-1])\n",
        "#bg=np.zeros(np.shape(image))\n",
        "visualize.display_instances(\n",
        "    image, r['rois'], r['masks'], r['class_ids'],\n",
        "    dataset.class_names, r['scores'],\n",
        "    show_bbox=False, show_mask=False,\n",
        "    title=\"Predictions\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqm6YUJgy8OK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhc6VQnFy8OP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E84KD59y8OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################\n",
        "#  Detection\n",
        "############################################################\n",
        "\n",
        "def detect(model, dataset_dir, subset):\n",
        "    \"\"\"Run detection on images in the given directory.\"\"\"\n",
        "    print(\"Running on {}\".format(dataset_dir))\n",
        "\n",
        "    # Create directory\n",
        "    if not os.path.exists(RESULTS_DIR):\n",
        "        os.makedirs(RESULTS_DIR)\n",
        "    submit_dir = \"submit_{:%Y%m%dT%H%M%S}\".format(datetime.datetime.now())\n",
        "    submit_dir = os.path.join(RESULTS_DIR, submit_dir)\n",
        "    os.makedirs(submit_dir)\n",
        "\n",
        "    # Read dataset\n",
        "    dataset = CellDataset()\n",
        "    dataset.load_cells(dataset_dir, subset)\n",
        "    dataset.prepare()\n",
        "    # Load over images\n",
        "    submission = []\n",
        "    for image_id in dataset.image_ids:\n",
        "        # Load image and run detection\n",
        "        image = dataset.load_image(image_id)\n",
        "        # Detect objects\n",
        "        r = model.detect([image], verbose=0)[0]\n",
        "        # Encode image to RLE. Returns a string of multiple lines\n",
        "        source_id = dataset.image_info[image_id][\"id\"]\n",
        "        rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
        "        submission.append(rle)\n",
        "        # Save image with masks\n",
        "        visualize.display_instances(\n",
        "            image, r['rois'], r['masks'], r['class_ids'],\n",
        "            dataset.class_names, r['scores'],\n",
        "            show_bbox=False, show_mask=False,\n",
        "            title=\"Predictions\")\n",
        "        plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))\n",
        "\n",
        "    # Save to csv file\n",
        "    submission = \"ImageId,EncodedPixels\\n\" + \"\\n\".join(submission)\n",
        "    file_path = os.path.join(submit_dir, \"submit.csv\")\n",
        "    with open(file_path, \"w\") as f:\n",
        "        f.write(submission)\n",
        "    print(\"Saved to \", submit_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf-Dlmoly8OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.max(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHXCLCily8Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}