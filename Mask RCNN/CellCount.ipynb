{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "CellCount.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVH-tWxvGpWg",
        "colab_type": "text"
      },
      "source": [
        "## Set up\n",
        "\n",
        "The first cell configures the Google Colab environment to allow the repo to execute properly. Simply \"Run All\" to get started."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42XoC_v9FRNC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "665c4362-8bd5-4836-c924-2d43b32b1265"
      },
      "source": [
        "# Necessary installs to get code working on Google colab\n",
        "!pip install libtiff\n",
        "!git clone https://github.com/Shu244/Cytometry-for-Google-Colab.git\n",
        "\n",
        "# Updating environment variables\n",
        "import sys\n",
        "sys.path.append(\"/content/Cytometry-for-Google-Colab/Mask RCNN\")\n",
        "\n",
        "# Downgrading Tensorflow version\n",
        "!pip install tensorflow-gpu==1.12.0\n",
        "!pip install tensorflow==1.12.0\n",
        "\n",
        "import tensorflow as tf\n",
        "assert (tf.__version__ == \"1.12.0\"), \"Restart runtime to use newly installed Tensorflow\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: libtiff in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "fatal: destination path 'Cytometry-for-Google-Colab' already exists and is not an empty directory.\n",
            "Requirement already satisfied: tensorflow-gpu==1.12.0 in /usr/local/lib/python3.6/dist-packages (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.28.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.18.3)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.12.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.9.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.3.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.12.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.12.0) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0) (1.0.1)\n",
            "Collecting tensorflow==1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.28.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.18.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.9.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0) (46.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (1.0.1)\n",
            "Installing collected packages: tensorflow\n",
            "  Found existing installation: tensorflow 2.2.0rc3\n",
            "    Uninstalling tensorflow-2.2.0rc3:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc3\n",
            "Successfully installed tensorflow-1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:09:15.022782Z",
          "start_time": "2020-04-15T21:09:02.480621Z"
        },
        "id": "fWMgiLuZy8Np",
        "colab_type": "code",
        "outputId": "f5c5fa0a-f2dd-455d-abe4-3d65a997de52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Set matplotlib backend\n",
        "# This has to be done before other importa that might\n",
        "# set it, but only if we're running in script mode\n",
        "# rather than being imported.\n",
        "'''\n",
        "if __name__ == '__main__':\n",
        "    import matplotlib\n",
        "    # Agg backend runs without a display\n",
        "    matplotlib.use('Agg')\n",
        "    import matplotlib.pyplot as plt\n",
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import json\n",
        "import datetime\n",
        "import xlrd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "from imgaug import augmenters as iaa\n",
        "from libtiff import TIFF, TIFFfile\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Results directory\n",
        "# Save submission files here\n",
        "RESULTS_DIR = os.path.join(ROOT_DIR, \"results/cellcount/\")\n",
        "\n",
        "from MRCNN.config import Config\n",
        "import MRCNN.model as modellib\n",
        "from MRCNN import utils, visualize\n",
        "\n",
        "DataSize=100\n",
        "Validation_ratio=0.1\n",
        "Data_IDS=np.arange(1,DataSize+1,dtype=np.int16) \n",
        "VAL_IMAGE_IDS = np.random.choice(Data_IDS,size=np.int(Validation_ratio*DataSize),replace=False)\n",
        "VAL_IMAGE_IDS.sort()\n",
        "\n",
        "#####################################################\n",
        "#         Configuration\n",
        "#####################################################\n",
        "class CellCountConfig(Config):\n",
        "    NAME = 'CellCount'\n",
        "    \n",
        "    # Train on 1 GPU and 2 images per GPU.\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1 # Background + RedBloodCell\n",
        "    \n",
        "    # Don't exclude based on confidence. Since we have two classes\n",
        "    # then 0.5 is the minimum anyway as it picks between nucleus and BG\n",
        "    DETECTION_MIN_CONFIDENCE = 0\n",
        "    \n",
        "    # Backbone network architecture\n",
        "    # Supported values are: resnet50, resnet101\n",
        "    BACKBONE = \"resnet101\"\n",
        "    \n",
        "    # Input image resizing\n",
        "    IMAGE_RESIZE_MODE = \"pad64\"\n",
        "    IMAGE_MIN_DIM = 812\n",
        "    IMAGE_MAX_DIM = 1280\n",
        "    IMAGE_SHAPE= (832, 1280, 3)\n",
        "    \n",
        "    IMAGE_CHANNEL_COUNT = 3   \n",
        "    \n",
        "    # Length of square anchor side in pixels\n",
        "    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)\n",
        "    \n",
        "    # Number of ROIs per image to feed to classifier/mask heads\n",
        "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
        "    # enough positive proposals to fill this and keep a positive:negative\n",
        "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
        "    # the RPN NMS threshold.\n",
        "    TRAIN_ROIS_PER_IMAGE = 128\n",
        "\n",
        "    # Maximum number of ground truth instances to use in one image\n",
        "    MAX_GT_INSTANCES = 100\n",
        "\n",
        "    # Max number of final detections per image\n",
        "    DETECTION_MAX_INSTANCES = 200\n",
        "    \n",
        "    \n",
        "    # Use a small epoch since the data is simple\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    # use small validation steps since the epoch is small\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "    \n",
        "    # Non-max suppression threshold to filter RPN proposals.\n",
        "    # You can increase this during training to generate more propsals.\n",
        "    #RPN_NMS_THRESHOLD = 0.9\n",
        "    RPN_NMS_THRESHOLD=0.95\n",
        "    \n",
        "    # ROIs kept after non-maximum supression (training and inference)\n",
        "    POST_NMS_ROIS_TRAINING = 500\n",
        "    POST_NMS_ROIS_INFERENCE = 1000\n",
        "    \n",
        "    # Image mean (RGB)\n",
        "    MEAN_PIXEL = (126,126,126)\n",
        "        \n",
        "    # If enabled, resizes instance masks to a smaller size to reduce\n",
        "    # memory load. Recommended when using high-resolution images.\n",
        "    USE_MINI_MASK = True\n",
        "    #MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
        "    MINI_MASK_SHAPE = (100,100)\n",
        "\n",
        "    # Number of ROIs per image to feed to classifier/mask heads\n",
        "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
        "    # enough positive proposals to fill this and keep a positive:negative\n",
        "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
        "    # the RPN NMS threshold.\n",
        "    #TRAIN_ROIS_PER_IMAGE = 128\n",
        "    TRAIN_ROIS_PER_IMAGE = 256\n",
        "    \n",
        "\n",
        "#####################################################\n",
        "#         Dataset\n",
        "#####################################################\n",
        "class CellDataset(utils.Dataset):\n",
        "    \n",
        "    def Image_gen(self, FileName):\n",
        "        self.frame=0\n",
        "        self.ImgeFile=FileName\n",
        "        tif=TIFF.open(FileName)\n",
        "        for Image_gened in tif.iter_images():\n",
        "        #Image = imread(FileName,1)\n",
        "            self.frame+=1\n",
        "            yield Image_gened  \n",
        "    \n",
        "    def Image_getFrame(self, Image_dir, Frame):\n",
        "        #if self.ImgeFile!=Image_dir or self.frame > Frame:\n",
        "        Image_gen=self.Image_gen(Image_dir)\n",
        "        self.frame=0\n",
        "        im_getFrame=[]\n",
        "        while self.frame<Frame:\n",
        "            im_getFrame= next(Image_gen)\n",
        "        im_getFrame=np.array(im_getFrame)\n",
        "        return im_getFrame\n",
        "            \n",
        "    def load_cells(self, dataset_dir, subset):\n",
        "        \"\"\"\n",
        "        Load a subset of the cell dataset.\n",
        "        dataset_dir: Root directory of the dataset\n",
        "        subset: Subset to load. \n",
        "                * train: training data excluding validation images\n",
        "                * val: validation images from VAL_IMAGE_IDS\n",
        "        \"\"\"\n",
        "\n",
        "        # Add classes. We have one class.\n",
        "        # Naming the dataset Cells, and the 1st class RedBloodCell\n",
        "        self.add_class(\"Cells\", 1, \"RBC\")\n",
        "        ROOT_PATH=os.path.dirname(os.getcwd())\n",
        "        dataset_dir=os.path.join(ROOT_PATH,\"Data\",dataset_dir)\n",
        "       # Train or validation dataset?\n",
        "        assert subset in [\"train\", \"val\"]\n",
        "        if subset == \"val\":\n",
        "            image_ids = VAL_IMAGE_IDS\n",
        "        else:\n",
        "            # Get image ids from directory names\n",
        "            if subset == \"train\":\n",
        "                image_ids = list(set(Data_IDS) - set(VAL_IMAGE_IDS))\n",
        "        # Add images\n",
        "        for image_id in image_ids:\n",
        "            self.add_image(\n",
        "                \"Cells\",\n",
        "                image_id=image_id,\n",
        "                path=dataset_dir)\n",
        "                  \n",
        "    def load_image (self,image_id):\n",
        "        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
        "        \"\"\"\n",
        "        # Load image\n",
        "        info = self.image_info[image_id]\n",
        "        dataset_dir=info['path']\n",
        "        data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
        "        data=data.sheets()[0]\n",
        "        Image_dir=os.path.join(os.path.dirname(os.getcwd()),data.col_values(0)[1])\n",
        "        image=self.Image_getFrame(Image_dir, info['id'])\n",
        "        # If grayscale. Convert to RGB for consistency.\n",
        "        image=(image/np.max(image)*255).astype(np.float16)\n",
        "        if image.ndim != 3:\n",
        "            image = skimage.color.gray2rgb(image)\n",
        "        # If has an alpha channel, remove it for consistency\n",
        "        if image.shape[-1] == 4:\n",
        "            image = image[..., :3]\n",
        "        return image\n",
        "        \n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        dataset_dir=info['path']\n",
        "        data=xlrd.open_workbook(os.path.join(dataset_dir,'cellLabel.xlsx'))\n",
        "        data=data.sheets()[0]\n",
        "        Frame=data.col_values(1)[1:]\n",
        "        ClassName=data.col_values(2)[1:]\n",
        "        \n",
        "        MaskNum=data.col_values(4)[1:]\n",
        "        ImgMask = [(Class,ImgMask) for [Class,ImgMask,frame] in zip(ClassName, MaskNum,Frame) if frame==info['id']]\n",
        "        # Read mask files from .tif image\n",
        "        Mask=[]\n",
        "        ClassID=[]\n",
        "        for i,Img in enumerate(ImgMask):\n",
        "            # Get mask directory from image path\n",
        "            mask_dir = os.path.join(info['path'], \"{}.tif\".format(Img[1]))\n",
        "            #ID=[name['id'] for name in (self.class_info) if name.get('name')==Img[0]]\n",
        "            ID=1\n",
        "            im = cv2.imread(mask_dir,0).astype(np.bool)\n",
        "            Mask.append(im)\n",
        "            ClassID.append(ID)\n",
        "        Mask = np.stack(Mask, axis=-1)\n",
        "        ClassID= np.squeeze(np.array(ClassID))\n",
        "        return Mask,ClassID\n",
        "    \n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"cells\":\n",
        "            return info[\"id\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n",
        "\n",
        "############################################################\n",
        "#  Training\n",
        "############################################################\n",
        "\n",
        "def train(model, dataset_dir, subset):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    # Training dataset.\n",
        "    dataset_train = CellDataset()\n",
        "    dataset_train.load_cells(dataset_dir,\"train\")\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    # Validation dataset\n",
        "    dataset_val = CellDataset()\n",
        "    dataset_val.load_cells(dataset_dir, \"val\")\n",
        "    dataset_val.prepare()\n",
        "    \n",
        "    # Image augmentation\n",
        "    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n",
        "    augmentation = iaa.SomeOf((0, 2), [\n",
        "        iaa.Fliplr(0.5),\n",
        "        iaa.Flipud(0.5),\n",
        "        iaa.OneOf([iaa.Affine(rotate=90),\n",
        "                   iaa.Affine(rotate=180),\n",
        "                   iaa.Affine(rotate=270)]),\n",
        "        iaa.Multiply((0.8, 1.5)),\n",
        "        iaa.GaussianBlur(sigma=(0.0, 5.0))\n",
        "    ])\n",
        "\n",
        "    # If starting from imagenet, train heads only for a bit\n",
        "    # since they have random weights\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                augmentation=augmentation,\n",
        "                epochs=15,\n",
        "                layers='4+')\n",
        "    '''\n",
        "    print(\"Train all layers\")\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=40,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n",
        "    '''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:22:53.550849Z",
          "start_time": "2020-04-15T21:09:22.980050Z"
        },
        "scrolled": false,
        "id": "17HIwHsny8Ny",
        "colab_type": "code",
        "outputId": "c06b22f7-4bd0-434c-b29a-8139fa36b86d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
        "    config = CellCountConfig()\n",
        "    #config.display()\n",
        "\n",
        "    # Create model\n",
        "    model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=RESULTS_DIR)\n",
        "\n",
        "    #Load COCO weights\n",
        "    COCO_WEIGHTS_PATH = os.path.join(os.path.dirname(ROOT_DIR), \"mask_rcnn_coco.h5\")\n",
        "    weights_path= COCO_WEIGHTS_PATH\n",
        "    #weights_path = model.get_imagenet_weights()\n",
        "    # Load weights\n",
        "    model.load_weights(weights_path, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "    #model.load_weights(weights_path, by_name=True)\n",
        "    train(model=model, dataset_dir='val', subset='train')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5d57dc3575e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodellib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRESULTS_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#Load COCO weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mode, config, model_dir)\u001b[0m\n\u001b[1;32m   1833\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_log_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1835\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, mode, config)\u001b[0m\n\u001b[1;32m   1986\u001b[0m             \u001b[0mrois\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_bbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1987\u001b[0m                 DetectionTargetLayer(config, name=\"proposal_targets\")([\n\u001b[0;32m-> 1988\u001b[0;31m                     target_rois, input_gt_class_ids, gt_boxes, input_gt_masks])\n\u001b[0m\u001b[1;32m   1989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1990\u001b[0m             \u001b[0;31m# Network Heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    662\u001b[0m             lambda w, x, y, z: detection_targets_graph(\n\u001b[1;32m    663\u001b[0m                 w, x, y, z, self.config),\n\u001b[0;32m--> 664\u001b[0;31m             self.config.IMAGES_PER_GPU, names=names)\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/utils.py\u001b[0m in \u001b[0;36mbatch_slice\u001b[0;34m(inputs, graph_fn, batch_size, names)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0minputs_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         \u001b[0moutput_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0moutput_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(w, x, y, z)\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_class_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_masks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             lambda w, x, y, z: detection_targets_graph(\n\u001b[0;32m--> 663\u001b[0;31m                 w, x, y, z, self.config),\n\u001b[0m\u001b[1;32m    664\u001b[0m             self.config.IMAGES_PER_GPU, names=names)\n\u001b[1;32m    665\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/model.py\u001b[0m in \u001b[0;36mdetection_targets_graph\u001b[0;34m(proposals, gt_class_ids, gt_boxes, gt_masks, config)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;31m# Compute bbox refinement for positive ROIs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_refinement_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_rois\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_gt_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m     \u001b[0mdeltas\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBBOX_STD_DEV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Cytometry-for-Google-Colab/Mask RCNN/MRCNN/utils.py\u001b[0m in \u001b[0;36mbox_refinement_graph\u001b[0;34m(box, gt_box)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgt_center_y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcenter_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgt_center_x\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcenter_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mdh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_height\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mdw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_width\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'log'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:26:24.856692Z",
          "start_time": "2020-04-15T21:26:11.833656Z"
        },
        "id": "rlgYbX73y8N3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################\n",
        "#  Detection\n",
        "############################################################\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
        "config = CellCountConfig()\n",
        "\n",
        "#Create Model\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=RESULTS_DIR)\n",
        "\n",
        "#Load weights\n",
        "weights_path= \"results/cellcount/cellcount20200129T0945/mask_rcnn_cellcount_0015.h5\"\n",
        "# Load weights\n",
        "model.load_weights(weights_path, by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-15T21:30:39.947165Z",
          "start_time": "2020-04-15T21:30:13.315439Z"
        },
        "id": "Guz4JPA6y8N8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read dataset\n",
        "dataset = CellDataset()\n",
        "dataset.load_cells('val', 'train')\n",
        "dataset.prepare()\n",
        "\n",
        "GT_no=[]\n",
        "DE_no=[]\n",
        "for image_id in range (1,28):\n",
        "    # Load image and run detection\n",
        "    image = dataset.load_image(image_id)\n",
        "    mask,class_id= dataset.load_mask(image_id)\n",
        "    # Detect objects\n",
        "    r = model.detect([image], verbose=0)[0]\n",
        "    # Encode image to RLE. Returns a string of multiple lines\n",
        "    source_id = dataset.image_info[image_id][\"id\"]\n",
        "    #rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
        "    #submission.append(rle)\n",
        "    GT_no.append(np.size(mask,2))\n",
        "    DE_no.append(len(r['class_ids']))\n",
        "    print('--------------------------------')\n",
        "    print('Frame ID =', dataset.image_info[image_id][\"id\"])\n",
        "    print('Ground Truth Cell Number = ', GT_no[-1])\n",
        "    print('Detected Cell Number =', DE_no[-1])\n",
        "    visualize.display_instances(\n",
        "        np.sum(mask,axis=2), r['rois'], r['masks'], r['class_ids'],\n",
        "        dataset.class_names, r['scores'],\n",
        "        show_bbox=False, show_mask=False,\n",
        "        title=\"Predictions\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "GkVJoLK-y8OD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read dataset\n",
        "dataset = CellDataset()\n",
        "dataset.load_cells('val', 'train')\n",
        "dataset.prepare()\n",
        "im_dir='../GFC_505nm_40X1p15NA_PCO_500usexp_160fps_3@0001.tif'\n",
        "image =dataset.Image_getFrame(im_dir,27)\n",
        "if image.ndim != 3:\n",
        "    image = skimage.color.gray2rgb(image)\n",
        "# If has an alpha channel, remove it for consistency\n",
        "if image.shape[-1] == 4:\n",
        "    image = image[..., :3]\n",
        "image=(image/np.max(image)*255).astype(np.float16)\n",
        "# Detect objects\n",
        "r = model.detect([image], verbose=0)[0]\n",
        "# Encode image to RLE. Returns a string of multiple lines\n",
        "source_id = dataset.image_info[image_id][\"id\"]\n",
        "#rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
        "#submission.append(rle)\n",
        "GT_no.append(np.size(mask,2))\n",
        "DE_no.append(len(r['class_ids']))\n",
        "print('--------------------------------')\n",
        "print('Frame ID =', dataset.image_info[image_id][\"id\"])\n",
        "print('Ground Truth Cell Number = ', GT_no[-1])\n",
        "print('Detected Cell Number =', DE_no[-1])\n",
        "#bg=np.zeros(np.shape(image))\n",
        "visualize.display_instances(\n",
        "    image, r['rois'], r['masks'], r['class_ids'],\n",
        "    dataset.class_names, r['scores'],\n",
        "    show_bbox=False, show_mask=False,\n",
        "    title=\"Predictions\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqm6YUJgy8OK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhc6VQnFy8OP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E84KD59y8OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################\n",
        "#  Detection\n",
        "############################################################\n",
        "\n",
        "def detect(model, dataset_dir, subset):\n",
        "    \"\"\"Run detection on images in the given directory.\"\"\"\n",
        "    print(\"Running on {}\".format(dataset_dir))\n",
        "\n",
        "    # Create directory\n",
        "    if not os.path.exists(RESULTS_DIR):\n",
        "        os.makedirs(RESULTS_DIR)\n",
        "    submit_dir = \"submit_{:%Y%m%dT%H%M%S}\".format(datetime.datetime.now())\n",
        "    submit_dir = os.path.join(RESULTS_DIR, submit_dir)\n",
        "    os.makedirs(submit_dir)\n",
        "\n",
        "    # Read dataset\n",
        "    dataset = CellDataset()\n",
        "    dataset.load_cells(dataset_dir, subset)\n",
        "    dataset.prepare()\n",
        "    # Load over images\n",
        "    submission = []\n",
        "    for image_id in dataset.image_ids:\n",
        "        # Load image and run detection\n",
        "        image = dataset.load_image(image_id)\n",
        "        # Detect objects\n",
        "        r = model.detect([image], verbose=0)[0]\n",
        "        # Encode image to RLE. Returns a string of multiple lines\n",
        "        source_id = dataset.image_info[image_id][\"id\"]\n",
        "        rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
        "        submission.append(rle)\n",
        "        # Save image with masks\n",
        "        visualize.display_instances(\n",
        "            image, r['rois'], r['masks'], r['class_ids'],\n",
        "            dataset.class_names, r['scores'],\n",
        "            show_bbox=False, show_mask=False,\n",
        "            title=\"Predictions\")\n",
        "        plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))\n",
        "\n",
        "    # Save to csv file\n",
        "    submission = \"ImageId,EncodedPixels\\n\" + \"\\n\".join(submission)\n",
        "    file_path = os.path.join(submit_dir, \"submit.csv\")\n",
        "    with open(file_path, \"w\") as f:\n",
        "        f.write(submission)\n",
        "    print(\"Saved to \", submit_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf-Dlmoly8OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.max(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHXCLCily8Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}